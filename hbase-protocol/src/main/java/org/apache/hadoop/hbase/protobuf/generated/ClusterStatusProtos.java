// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: ClusterStatus.proto

package org.apache.hadoop.hbase.protobuf.generated;

public final class ClusterStatusProtos {
  private ClusterStatusProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  public interface RegionStateOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionInfo region_info = 1;
    boolean hasRegionInfo();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder();
    
    // required .RegionState.State state = 2;
    boolean hasState();
    org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State getState();
    
    // optional uint64 stamp = 3;
    boolean hasStamp();
    long getStamp();
  }
  public static final class RegionState extends
      com.google.protobuf.GeneratedMessage
      implements RegionStateOrBuilder {
    // Use RegionState.newBuilder() to construct.
    private RegionState(Builder builder) {
      super(builder);
    }
    private RegionState(boolean noInit) {}
    
    private static final RegionState defaultInstance;
    public static RegionState getDefaultInstance() {
      return defaultInstance;
    }
    
    public RegionState getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionState_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionState_fieldAccessorTable;
    }
    
    public enum State
        implements com.google.protobuf.ProtocolMessageEnum {
      OFFLINE(0, 0),
      PENDING_OPEN(1, 1),
      OPENING(2, 2),
      OPEN(3, 3),
      PENDING_CLOSE(4, 4),
      CLOSING(5, 5),
      CLOSED(6, 6),
      SPLITTING(7, 7),
      SPLIT(8, 8),
      FAILED_OPEN(9, 9),
      FAILED_CLOSE(10, 10),
      MERGING(11, 11),
      MERGED(12, 12),
      ;
      
      public static final int OFFLINE_VALUE = 0;
      public static final int PENDING_OPEN_VALUE = 1;
      public static final int OPENING_VALUE = 2;
      public static final int OPEN_VALUE = 3;
      public static final int PENDING_CLOSE_VALUE = 4;
      public static final int CLOSING_VALUE = 5;
      public static final int CLOSED_VALUE = 6;
      public static final int SPLITTING_VALUE = 7;
      public static final int SPLIT_VALUE = 8;
      public static final int FAILED_OPEN_VALUE = 9;
      public static final int FAILED_CLOSE_VALUE = 10;
      public static final int MERGING_VALUE = 11;
      public static final int MERGED_VALUE = 12;
      
      
      public final int getNumber() { return value; }
      
      public static State valueOf(int value) {
        switch (value) {
          case 0: return OFFLINE;
          case 1: return PENDING_OPEN;
          case 2: return OPENING;
          case 3: return OPEN;
          case 4: return PENDING_CLOSE;
          case 5: return CLOSING;
          case 6: return CLOSED;
          case 7: return SPLITTING;
          case 8: return SPLIT;
          case 9: return FAILED_OPEN;
          case 10: return FAILED_CLOSE;
          case 11: return MERGING;
          case 12: return MERGED;
          default: return null;
        }
      }
      
      public static com.google.protobuf.Internal.EnumLiteMap<State>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<State>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<State>() {
              public State findValueByNumber(int number) {
                return State.valueOf(number);
              }
            };
      
      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.getDescriptor().getEnumTypes().get(0);
      }
      
      private static final State[] VALUES = {
        OFFLINE, PENDING_OPEN, OPENING, OPEN, PENDING_CLOSE, CLOSING, CLOSED, SPLITTING, SPLIT, FAILED_OPEN, FAILED_CLOSE, MERGING, MERGED, 
      };
      
      public static State valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }
      
      private final int index;
      private final int value;
      
      private State(int index, int value) {
        this.index = index;
        this.value = value;
      }
      
      // @@protoc_insertion_point(enum_scope:RegionState.State)
    }
    
    private int bitField0_;
    // required .RegionInfo region_info = 1;
    public static final int REGION_INFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo regionInfo_;
    public boolean hasRegionInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
      return regionInfo_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
      return regionInfo_;
    }
    
    // required .RegionState.State state = 2;
    public static final int STATE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State state_;
    public boolean hasState() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State getState() {
      return state_;
    }
    
    // optional uint64 stamp = 3;
    public static final int STAMP_FIELD_NUMBER = 3;
    private long stamp_;
    public boolean hasStamp() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public long getStamp() {
      return stamp_;
    }
    
    private void initFields() {
      regionInfo_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance();
      state_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State.OFFLINE;
      stamp_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRegionInfo()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasState()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionInfo().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, regionInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, state_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt64(3, stamp_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, regionInfo_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, state_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, stamp_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState other = (org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState) obj;
      
      boolean result = true;
      result = result && (hasRegionInfo() == other.hasRegionInfo());
      if (hasRegionInfo()) {
        result = result && getRegionInfo()
            .equals(other.getRegionInfo());
      }
      result = result && (hasState() == other.hasState());
      if (hasState()) {
        result = result &&
            (getState() == other.getState());
      }
      result = result && (hasStamp() == other.hasStamp());
      if (hasStamp()) {
        result = result && (getStamp()
            == other.getStamp());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegionInfo()) {
        hash = (37 * hash) + REGION_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getRegionInfo().hashCode();
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getState());
      }
      if (hasStamp()) {
        hash = (37 * hash) + STAMP_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getStamp());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionStateOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionState_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionState_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionInfoFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionInfoBuilder_ == null) {
          regionInfo_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance();
        } else {
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        state_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State.OFFLINE;
        bitField0_ = (bitField0_ & ~0x00000002);
        stamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState build() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState result = new org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionInfoBuilder_ == null) {
          result.regionInfo_ = regionInfo_;
        } else {
          result.regionInfo_ = regionInfoBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.state_ = state_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.stamp_ = stamp_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.getDefaultInstance()) return this;
        if (other.hasRegionInfo()) {
          mergeRegionInfo(other.getRegionInfo());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (other.hasStamp()) {
          setStamp(other.getStamp());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRegionInfo()) {
          
          return false;
        }
        if (!hasState()) {
          
          return false;
        }
        if (!getRegionInfo().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.newBuilder();
              if (hasRegionInfo()) {
                subBuilder.mergeFrom(getRegionInfo());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegionInfo(subBuilder.buildPartial());
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State value = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                state_ = value;
              }
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              stamp_ = input.readUInt64();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionInfo region_info = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo regionInfo_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> regionInfoBuilder_;
      public boolean hasRegionInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getRegionInfo() {
        if (regionInfoBuilder_ == null) {
          return regionInfo_;
        } else {
          return regionInfoBuilder_.getMessage();
        }
      }
      public Builder setRegionInfo(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionInfo_ = value;
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegionInfo(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder builderForValue) {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = builderForValue.build();
          onChanged();
        } else {
          regionInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegionInfo(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo value) {
        if (regionInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              regionInfo_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) {
            regionInfo_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.newBuilder(regionInfo_).mergeFrom(value).buildPartial();
          } else {
            regionInfo_ = value;
          }
          onChanged();
        } else {
          regionInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegionInfo() {
        if (regionInfoBuilder_ == null) {
          regionInfo_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance();
          onChanged();
        } else {
          regionInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder getRegionInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionInfoFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder getRegionInfoOrBuilder() {
        if (regionInfoBuilder_ != null) {
          return regionInfoBuilder_.getMessageOrBuilder();
        } else {
          return regionInfo_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder> 
          getRegionInfoFieldBuilder() {
        if (regionInfoBuilder_ == null) {
          regionInfoBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder>(
                  regionInfo_,
                  getParentForChildren(),
                  isClean());
          regionInfo_ = null;
        }
        return regionInfoBuilder_;
      }
      
      // required .RegionState.State state = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State state_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State.OFFLINE;
      public boolean hasState() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State getState() {
        return state_;
      }
      public Builder setState(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        state_ = value;
        onChanged();
        return this;
      }
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000002);
        state_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.State.OFFLINE;
        onChanged();
        return this;
      }
      
      // optional uint64 stamp = 3;
      private long stamp_ ;
      public boolean hasStamp() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public long getStamp() {
        return stamp_;
      }
      public Builder setStamp(long value) {
        bitField0_ |= 0x00000004;
        stamp_ = value;
        onChanged();
        return this;
      }
      public Builder clearStamp() {
        bitField0_ = (bitField0_ & ~0x00000004);
        stamp_ = 0L;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:RegionState)
    }
    
    static {
      defaultInstance = new RegionState(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:RegionState)
  }
  
  public interface RegionInTransitionOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionSpecifier spec = 1;
    boolean hasSpec();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getSpec();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getSpecOrBuilder();
    
    // required .RegionState region_state = 2;
    boolean hasRegionState();
    org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState getRegionState();
    org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionStateOrBuilder getRegionStateOrBuilder();
  }
  public static final class RegionInTransition extends
      com.google.protobuf.GeneratedMessage
      implements RegionInTransitionOrBuilder {
    // Use RegionInTransition.newBuilder() to construct.
    private RegionInTransition(Builder builder) {
      super(builder);
    }
    private RegionInTransition(boolean noInit) {}
    
    private static final RegionInTransition defaultInstance;
    public static RegionInTransition getDefaultInstance() {
      return defaultInstance;
    }
    
    public RegionInTransition getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionInTransition_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionInTransition_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .RegionSpecifier spec = 1;
    public static final int SPEC_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier spec_;
    public boolean hasSpec() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getSpec() {
      return spec_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getSpecOrBuilder() {
      return spec_;
    }
    
    // required .RegionState region_state = 2;
    public static final int REGION_STATE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState regionState_;
    public boolean hasRegionState() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState getRegionState() {
      return regionState_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionStateOrBuilder getRegionStateOrBuilder() {
      return regionState_;
    }
    
    private void initFields() {
      spec_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      regionState_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasSpec()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasRegionState()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getSpec().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionState().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, spec_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, regionState_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, spec_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, regionState_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition other = (org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition) obj;
      
      boolean result = true;
      result = result && (hasSpec() == other.hasSpec());
      if (hasSpec()) {
        result = result && getSpec()
            .equals(other.getSpec());
      }
      result = result && (hasRegionState() == other.hasRegionState());
      if (hasRegionState()) {
        result = result && getRegionState()
            .equals(other.getRegionState());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasSpec()) {
        hash = (37 * hash) + SPEC_FIELD_NUMBER;
        hash = (53 * hash) + getSpec().hashCode();
      }
      if (hasRegionState()) {
        hash = (37 * hash) + REGION_STATE_FIELD_NUMBER;
        hash = (53 * hash) + getRegionState().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransitionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionInTransition_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionInTransition_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getSpecFieldBuilder();
          getRegionStateFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (specBuilder_ == null) {
          spec_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          specBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (regionStateBuilder_ == null) {
          regionState_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.getDefaultInstance();
        } else {
          regionStateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition build() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition result = new org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (specBuilder_ == null) {
          result.spec_ = spec_;
        } else {
          result.spec_ = specBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (regionStateBuilder_ == null) {
          result.regionState_ = regionState_;
        } else {
          result.regionState_ = regionStateBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.getDefaultInstance()) return this;
        if (other.hasSpec()) {
          mergeSpec(other.getSpec());
        }
        if (other.hasRegionState()) {
          mergeRegionState(other.getRegionState());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasSpec()) {
          
          return false;
        }
        if (!hasRegionState()) {
          
          return false;
        }
        if (!getSpec().isInitialized()) {
          
          return false;
        }
        if (!getRegionState().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasSpec()) {
                subBuilder.mergeFrom(getSpec());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setSpec(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.newBuilder();
              if (hasRegionState()) {
                subBuilder.mergeFrom(getRegionState());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegionState(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionSpecifier spec = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier spec_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> specBuilder_;
      public boolean hasSpec() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getSpec() {
        if (specBuilder_ == null) {
          return spec_;
        } else {
          return specBuilder_.getMessage();
        }
      }
      public Builder setSpec(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (specBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          spec_ = value;
          onChanged();
        } else {
          specBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setSpec(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (specBuilder_ == null) {
          spec_ = builderForValue.build();
          onChanged();
        } else {
          specBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeSpec(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (specBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              spec_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            spec_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(spec_).mergeFrom(value).buildPartial();
          } else {
            spec_ = value;
          }
          onChanged();
        } else {
          specBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearSpec() {
        if (specBuilder_ == null) {
          spec_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          specBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getSpecBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getSpecFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getSpecOrBuilder() {
        if (specBuilder_ != null) {
          return specBuilder_.getMessageOrBuilder();
        } else {
          return spec_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getSpecFieldBuilder() {
        if (specBuilder_ == null) {
          specBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  spec_,
                  getParentForChildren(),
                  isClean());
          spec_ = null;
        }
        return specBuilder_;
      }
      
      // required .RegionState region_state = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState regionState_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionStateOrBuilder> regionStateBuilder_;
      public boolean hasRegionState() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState getRegionState() {
        if (regionStateBuilder_ == null) {
          return regionState_;
        } else {
          return regionStateBuilder_.getMessage();
        }
      }
      public Builder setRegionState(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState value) {
        if (regionStateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionState_ = value;
          onChanged();
        } else {
          regionStateBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setRegionState(
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.Builder builderForValue) {
        if (regionStateBuilder_ == null) {
          regionState_ = builderForValue.build();
          onChanged();
        } else {
          regionStateBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeRegionState(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState value) {
        if (regionStateBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              regionState_ != org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.getDefaultInstance()) {
            regionState_ =
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.newBuilder(regionState_).mergeFrom(value).buildPartial();
          } else {
            regionState_ = value;
          }
          onChanged();
        } else {
          regionStateBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearRegionState() {
        if (regionStateBuilder_ == null) {
          regionState_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.getDefaultInstance();
          onChanged();
        } else {
          regionStateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.Builder getRegionStateBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getRegionStateFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionStateOrBuilder getRegionStateOrBuilder() {
        if (regionStateBuilder_ != null) {
          return regionStateBuilder_.getMessageOrBuilder();
        } else {
          return regionState_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionStateOrBuilder> 
          getRegionStateFieldBuilder() {
        if (regionStateBuilder_ == null) {
          regionStateBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionStateOrBuilder>(
                  regionState_,
                  getParentForChildren(),
                  isClean());
          regionState_ = null;
        }
        return regionStateBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:RegionInTransition)
    }
    
    static {
      defaultInstance = new RegionInTransition(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:RegionInTransition)
  }
  
  public interface RegionLoadOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionSpecifier region_specifier = 1;
    boolean hasRegionSpecifier();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegionSpecifier();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionSpecifierOrBuilder();
    
    // optional uint32 stores = 2;
    boolean hasStores();
    int getStores();
    
    // optional uint32 storefiles = 3;
    boolean hasStorefiles();
    int getStorefiles();
    
    // optional uint32 store_uncompressed_size_MB = 4;
    boolean hasStoreUncompressedSizeMB();
    int getStoreUncompressedSizeMB();
    
    // optional uint32 storefile_size_MB = 5;
    boolean hasStorefileSizeMB();
    int getStorefileSizeMB();
    
    // optional uint32 memstore_size_MB = 6;
    boolean hasMemstoreSizeMB();
    int getMemstoreSizeMB();
    
    // optional uint32 storefile_index_size_MB = 7;
    boolean hasStorefileIndexSizeMB();
    int getStorefileIndexSizeMB();
    
    // optional uint64 read_requests_count = 8;
    boolean hasReadRequestsCount();
    long getReadRequestsCount();
    
    // optional uint64 write_requests_count = 9;
    boolean hasWriteRequestsCount();
    long getWriteRequestsCount();
    
    // optional uint64 total_compacting_KVs = 10;
    boolean hasTotalCompactingKVs();
    long getTotalCompactingKVs();
    
    // optional uint64 current_compacted_KVs = 11;
    boolean hasCurrentCompactedKVs();
    long getCurrentCompactedKVs();
    
    // optional uint32 root_index_size_KB = 12;
    boolean hasRootIndexSizeKB();
    int getRootIndexSizeKB();
    
    // optional uint32 total_static_index_size_KB = 13;
    boolean hasTotalStaticIndexSizeKB();
    int getTotalStaticIndexSizeKB();
    
    // optional uint32 total_static_bloom_size_KB = 14;
    boolean hasTotalStaticBloomSizeKB();
    int getTotalStaticBloomSizeKB();
    
    // optional uint64 complete_sequence_id = 15;
    boolean hasCompleteSequenceId();
    long getCompleteSequenceId();
  }
  public static final class RegionLoad extends
      com.google.protobuf.GeneratedMessage
      implements RegionLoadOrBuilder {
    // Use RegionLoad.newBuilder() to construct.
    private RegionLoad(Builder builder) {
      super(builder);
    }
    private RegionLoad(boolean noInit) {}
    
    private static final RegionLoad defaultInstance;
    public static RegionLoad getDefaultInstance() {
      return defaultInstance;
    }
    
    public RegionLoad getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionLoad_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionLoad_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .RegionSpecifier region_specifier = 1;
    public static final int REGION_SPECIFIER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier regionSpecifier_;
    public boolean hasRegionSpecifier() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegionSpecifier() {
      return regionSpecifier_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionSpecifierOrBuilder() {
      return regionSpecifier_;
    }
    
    // optional uint32 stores = 2;
    public static final int STORES_FIELD_NUMBER = 2;
    private int stores_;
    public boolean hasStores() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public int getStores() {
      return stores_;
    }
    
    // optional uint32 storefiles = 3;
    public static final int STOREFILES_FIELD_NUMBER = 3;
    private int storefiles_;
    public boolean hasStorefiles() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public int getStorefiles() {
      return storefiles_;
    }
    
    // optional uint32 store_uncompressed_size_MB = 4;
    public static final int STORE_UNCOMPRESSED_SIZE_MB_FIELD_NUMBER = 4;
    private int storeUncompressedSizeMB_;
    public boolean hasStoreUncompressedSizeMB() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public int getStoreUncompressedSizeMB() {
      return storeUncompressedSizeMB_;
    }
    
    // optional uint32 storefile_size_MB = 5;
    public static final int STOREFILE_SIZE_MB_FIELD_NUMBER = 5;
    private int storefileSizeMB_;
    public boolean hasStorefileSizeMB() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    public int getStorefileSizeMB() {
      return storefileSizeMB_;
    }
    
    // optional uint32 memstore_size_MB = 6;
    public static final int MEMSTORE_SIZE_MB_FIELD_NUMBER = 6;
    private int memstoreSizeMB_;
    public boolean hasMemstoreSizeMB() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    public int getMemstoreSizeMB() {
      return memstoreSizeMB_;
    }
    
    // optional uint32 storefile_index_size_MB = 7;
    public static final int STOREFILE_INDEX_SIZE_MB_FIELD_NUMBER = 7;
    private int storefileIndexSizeMB_;
    public boolean hasStorefileIndexSizeMB() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    public int getStorefileIndexSizeMB() {
      return storefileIndexSizeMB_;
    }
    
    // optional uint64 read_requests_count = 8;
    public static final int READ_REQUESTS_COUNT_FIELD_NUMBER = 8;
    private long readRequestsCount_;
    public boolean hasReadRequestsCount() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    public long getReadRequestsCount() {
      return readRequestsCount_;
    }
    
    // optional uint64 write_requests_count = 9;
    public static final int WRITE_REQUESTS_COUNT_FIELD_NUMBER = 9;
    private long writeRequestsCount_;
    public boolean hasWriteRequestsCount() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    public long getWriteRequestsCount() {
      return writeRequestsCount_;
    }
    
    // optional uint64 total_compacting_KVs = 10;
    public static final int TOTAL_COMPACTING_KVS_FIELD_NUMBER = 10;
    private long totalCompactingKVs_;
    public boolean hasTotalCompactingKVs() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    public long getTotalCompactingKVs() {
      return totalCompactingKVs_;
    }
    
    // optional uint64 current_compacted_KVs = 11;
    public static final int CURRENT_COMPACTED_KVS_FIELD_NUMBER = 11;
    private long currentCompactedKVs_;
    public boolean hasCurrentCompactedKVs() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    public long getCurrentCompactedKVs() {
      return currentCompactedKVs_;
    }
    
    // optional uint32 root_index_size_KB = 12;
    public static final int ROOT_INDEX_SIZE_KB_FIELD_NUMBER = 12;
    private int rootIndexSizeKB_;
    public boolean hasRootIndexSizeKB() {
      return ((bitField0_ & 0x00000800) == 0x00000800);
    }
    public int getRootIndexSizeKB() {
      return rootIndexSizeKB_;
    }
    
    // optional uint32 total_static_index_size_KB = 13;
    public static final int TOTAL_STATIC_INDEX_SIZE_KB_FIELD_NUMBER = 13;
    private int totalStaticIndexSizeKB_;
    public boolean hasTotalStaticIndexSizeKB() {
      return ((bitField0_ & 0x00001000) == 0x00001000);
    }
    public int getTotalStaticIndexSizeKB() {
      return totalStaticIndexSizeKB_;
    }
    
    // optional uint32 total_static_bloom_size_KB = 14;
    public static final int TOTAL_STATIC_BLOOM_SIZE_KB_FIELD_NUMBER = 14;
    private int totalStaticBloomSizeKB_;
    public boolean hasTotalStaticBloomSizeKB() {
      return ((bitField0_ & 0x00002000) == 0x00002000);
    }
    public int getTotalStaticBloomSizeKB() {
      return totalStaticBloomSizeKB_;
    }
    
    // optional uint64 complete_sequence_id = 15;
    public static final int COMPLETE_SEQUENCE_ID_FIELD_NUMBER = 15;
    private long completeSequenceId_;
    public boolean hasCompleteSequenceId() {
      return ((bitField0_ & 0x00004000) == 0x00004000);
    }
    public long getCompleteSequenceId() {
      return completeSequenceId_;
    }
    
    private void initFields() {
      regionSpecifier_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      stores_ = 0;
      storefiles_ = 0;
      storeUncompressedSizeMB_ = 0;
      storefileSizeMB_ = 0;
      memstoreSizeMB_ = 0;
      storefileIndexSizeMB_ = 0;
      readRequestsCount_ = 0L;
      writeRequestsCount_ = 0L;
      totalCompactingKVs_ = 0L;
      currentCompactedKVs_ = 0L;
      rootIndexSizeKB_ = 0;
      totalStaticIndexSizeKB_ = 0;
      totalStaticBloomSizeKB_ = 0;
      completeSequenceId_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRegionSpecifier()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionSpecifier().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, regionSpecifier_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt32(2, stores_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt32(3, storefiles_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt32(4, storeUncompressedSizeMB_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeUInt32(5, storefileSizeMB_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeUInt32(6, memstoreSizeMB_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeUInt32(7, storefileIndexSizeMB_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeUInt64(8, readRequestsCount_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeUInt64(9, writeRequestsCount_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeUInt64(10, totalCompactingKVs_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeUInt64(11, currentCompactedKVs_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        output.writeUInt32(12, rootIndexSizeKB_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        output.writeUInt32(13, totalStaticIndexSizeKB_);
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        output.writeUInt32(14, totalStaticBloomSizeKB_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        output.writeUInt64(15, completeSequenceId_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, regionSpecifier_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, stores_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(3, storefiles_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, storeUncompressedSizeMB_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(5, storefileSizeMB_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(6, memstoreSizeMB_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(7, storefileIndexSizeMB_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(8, readRequestsCount_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(9, writeRequestsCount_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(10, totalCompactingKVs_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(11, currentCompactedKVs_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(12, rootIndexSizeKB_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(13, totalStaticIndexSizeKB_);
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(14, totalStaticBloomSizeKB_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(15, completeSequenceId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad other = (org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad) obj;
      
      boolean result = true;
      result = result && (hasRegionSpecifier() == other.hasRegionSpecifier());
      if (hasRegionSpecifier()) {
        result = result && getRegionSpecifier()
            .equals(other.getRegionSpecifier());
      }
      result = result && (hasStores() == other.hasStores());
      if (hasStores()) {
        result = result && (getStores()
            == other.getStores());
      }
      result = result && (hasStorefiles() == other.hasStorefiles());
      if (hasStorefiles()) {
        result = result && (getStorefiles()
            == other.getStorefiles());
      }
      result = result && (hasStoreUncompressedSizeMB() == other.hasStoreUncompressedSizeMB());
      if (hasStoreUncompressedSizeMB()) {
        result = result && (getStoreUncompressedSizeMB()
            == other.getStoreUncompressedSizeMB());
      }
      result = result && (hasStorefileSizeMB() == other.hasStorefileSizeMB());
      if (hasStorefileSizeMB()) {
        result = result && (getStorefileSizeMB()
            == other.getStorefileSizeMB());
      }
      result = result && (hasMemstoreSizeMB() == other.hasMemstoreSizeMB());
      if (hasMemstoreSizeMB()) {
        result = result && (getMemstoreSizeMB()
            == other.getMemstoreSizeMB());
      }
      result = result && (hasStorefileIndexSizeMB() == other.hasStorefileIndexSizeMB());
      if (hasStorefileIndexSizeMB()) {
        result = result && (getStorefileIndexSizeMB()
            == other.getStorefileIndexSizeMB());
      }
      result = result && (hasReadRequestsCount() == other.hasReadRequestsCount());
      if (hasReadRequestsCount()) {
        result = result && (getReadRequestsCount()
            == other.getReadRequestsCount());
      }
      result = result && (hasWriteRequestsCount() == other.hasWriteRequestsCount());
      if (hasWriteRequestsCount()) {
        result = result && (getWriteRequestsCount()
            == other.getWriteRequestsCount());
      }
      result = result && (hasTotalCompactingKVs() == other.hasTotalCompactingKVs());
      if (hasTotalCompactingKVs()) {
        result = result && (getTotalCompactingKVs()
            == other.getTotalCompactingKVs());
      }
      result = result && (hasCurrentCompactedKVs() == other.hasCurrentCompactedKVs());
      if (hasCurrentCompactedKVs()) {
        result = result && (getCurrentCompactedKVs()
            == other.getCurrentCompactedKVs());
      }
      result = result && (hasRootIndexSizeKB() == other.hasRootIndexSizeKB());
      if (hasRootIndexSizeKB()) {
        result = result && (getRootIndexSizeKB()
            == other.getRootIndexSizeKB());
      }
      result = result && (hasTotalStaticIndexSizeKB() == other.hasTotalStaticIndexSizeKB());
      if (hasTotalStaticIndexSizeKB()) {
        result = result && (getTotalStaticIndexSizeKB()
            == other.getTotalStaticIndexSizeKB());
      }
      result = result && (hasTotalStaticBloomSizeKB() == other.hasTotalStaticBloomSizeKB());
      if (hasTotalStaticBloomSizeKB()) {
        result = result && (getTotalStaticBloomSizeKB()
            == other.getTotalStaticBloomSizeKB());
      }
      result = result && (hasCompleteSequenceId() == other.hasCompleteSequenceId());
      if (hasCompleteSequenceId()) {
        result = result && (getCompleteSequenceId()
            == other.getCompleteSequenceId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegionSpecifier()) {
        hash = (37 * hash) + REGION_SPECIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getRegionSpecifier().hashCode();
      }
      if (hasStores()) {
        hash = (37 * hash) + STORES_FIELD_NUMBER;
        hash = (53 * hash) + getStores();
      }
      if (hasStorefiles()) {
        hash = (37 * hash) + STOREFILES_FIELD_NUMBER;
        hash = (53 * hash) + getStorefiles();
      }
      if (hasStoreUncompressedSizeMB()) {
        hash = (37 * hash) + STORE_UNCOMPRESSED_SIZE_MB_FIELD_NUMBER;
        hash = (53 * hash) + getStoreUncompressedSizeMB();
      }
      if (hasStorefileSizeMB()) {
        hash = (37 * hash) + STOREFILE_SIZE_MB_FIELD_NUMBER;
        hash = (53 * hash) + getStorefileSizeMB();
      }
      if (hasMemstoreSizeMB()) {
        hash = (37 * hash) + MEMSTORE_SIZE_MB_FIELD_NUMBER;
        hash = (53 * hash) + getMemstoreSizeMB();
      }
      if (hasStorefileIndexSizeMB()) {
        hash = (37 * hash) + STOREFILE_INDEX_SIZE_MB_FIELD_NUMBER;
        hash = (53 * hash) + getStorefileIndexSizeMB();
      }
      if (hasReadRequestsCount()) {
        hash = (37 * hash) + READ_REQUESTS_COUNT_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getReadRequestsCount());
      }
      if (hasWriteRequestsCount()) {
        hash = (37 * hash) + WRITE_REQUESTS_COUNT_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getWriteRequestsCount());
      }
      if (hasTotalCompactingKVs()) {
        hash = (37 * hash) + TOTAL_COMPACTING_KVS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getTotalCompactingKVs());
      }
      if (hasCurrentCompactedKVs()) {
        hash = (37 * hash) + CURRENT_COMPACTED_KVS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getCurrentCompactedKVs());
      }
      if (hasRootIndexSizeKB()) {
        hash = (37 * hash) + ROOT_INDEX_SIZE_KB_FIELD_NUMBER;
        hash = (53 * hash) + getRootIndexSizeKB();
      }
      if (hasTotalStaticIndexSizeKB()) {
        hash = (37 * hash) + TOTAL_STATIC_INDEX_SIZE_KB_FIELD_NUMBER;
        hash = (53 * hash) + getTotalStaticIndexSizeKB();
      }
      if (hasTotalStaticBloomSizeKB()) {
        hash = (37 * hash) + TOTAL_STATIC_BLOOM_SIZE_KB_FIELD_NUMBER;
        hash = (53 * hash) + getTotalStaticBloomSizeKB();
      }
      if (hasCompleteSequenceId()) {
        hash = (37 * hash) + COMPLETE_SEQUENCE_ID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getCompleteSequenceId());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionLoad_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_RegionLoad_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionSpecifierFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionSpecifierBuilder_ == null) {
          regionSpecifier_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionSpecifierBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        stores_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        storefiles_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        storeUncompressedSizeMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        storefileSizeMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000010);
        memstoreSizeMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000020);
        storefileIndexSizeMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000040);
        readRequestsCount_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000080);
        writeRequestsCount_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000100);
        totalCompactingKVs_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000200);
        currentCompactedKVs_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000400);
        rootIndexSizeKB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000800);
        totalStaticIndexSizeKB_ = 0;
        bitField0_ = (bitField0_ & ~0x00001000);
        totalStaticBloomSizeKB_ = 0;
        bitField0_ = (bitField0_ & ~0x00002000);
        completeSequenceId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00004000);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad build() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad result = new org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionSpecifierBuilder_ == null) {
          result.regionSpecifier_ = regionSpecifier_;
        } else {
          result.regionSpecifier_ = regionSpecifierBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.stores_ = stores_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.storefiles_ = storefiles_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.storeUncompressedSizeMB_ = storeUncompressedSizeMB_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.storefileSizeMB_ = storefileSizeMB_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.memstoreSizeMB_ = memstoreSizeMB_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.storefileIndexSizeMB_ = storefileIndexSizeMB_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.readRequestsCount_ = readRequestsCount_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.writeRequestsCount_ = writeRequestsCount_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.totalCompactingKVs_ = totalCompactingKVs_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000400;
        }
        result.currentCompactedKVs_ = currentCompactedKVs_;
        if (((from_bitField0_ & 0x00000800) == 0x00000800)) {
          to_bitField0_ |= 0x00000800;
        }
        result.rootIndexSizeKB_ = rootIndexSizeKB_;
        if (((from_bitField0_ & 0x00001000) == 0x00001000)) {
          to_bitField0_ |= 0x00001000;
        }
        result.totalStaticIndexSizeKB_ = totalStaticIndexSizeKB_;
        if (((from_bitField0_ & 0x00002000) == 0x00002000)) {
          to_bitField0_ |= 0x00002000;
        }
        result.totalStaticBloomSizeKB_ = totalStaticBloomSizeKB_;
        if (((from_bitField0_ & 0x00004000) == 0x00004000)) {
          to_bitField0_ |= 0x00004000;
        }
        result.completeSequenceId_ = completeSequenceId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.getDefaultInstance()) return this;
        if (other.hasRegionSpecifier()) {
          mergeRegionSpecifier(other.getRegionSpecifier());
        }
        if (other.hasStores()) {
          setStores(other.getStores());
        }
        if (other.hasStorefiles()) {
          setStorefiles(other.getStorefiles());
        }
        if (other.hasStoreUncompressedSizeMB()) {
          setStoreUncompressedSizeMB(other.getStoreUncompressedSizeMB());
        }
        if (other.hasStorefileSizeMB()) {
          setStorefileSizeMB(other.getStorefileSizeMB());
        }
        if (other.hasMemstoreSizeMB()) {
          setMemstoreSizeMB(other.getMemstoreSizeMB());
        }
        if (other.hasStorefileIndexSizeMB()) {
          setStorefileIndexSizeMB(other.getStorefileIndexSizeMB());
        }
        if (other.hasReadRequestsCount()) {
          setReadRequestsCount(other.getReadRequestsCount());
        }
        if (other.hasWriteRequestsCount()) {
          setWriteRequestsCount(other.getWriteRequestsCount());
        }
        if (other.hasTotalCompactingKVs()) {
          setTotalCompactingKVs(other.getTotalCompactingKVs());
        }
        if (other.hasCurrentCompactedKVs()) {
          setCurrentCompactedKVs(other.getCurrentCompactedKVs());
        }
        if (other.hasRootIndexSizeKB()) {
          setRootIndexSizeKB(other.getRootIndexSizeKB());
        }
        if (other.hasTotalStaticIndexSizeKB()) {
          setTotalStaticIndexSizeKB(other.getTotalStaticIndexSizeKB());
        }
        if (other.hasTotalStaticBloomSizeKB()) {
          setTotalStaticBloomSizeKB(other.getTotalStaticBloomSizeKB());
        }
        if (other.hasCompleteSequenceId()) {
          setCompleteSequenceId(other.getCompleteSequenceId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRegionSpecifier()) {
          
          return false;
        }
        if (!getRegionSpecifier().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasRegionSpecifier()) {
                subBuilder.mergeFrom(getRegionSpecifier());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegionSpecifier(subBuilder.buildPartial());
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              stores_ = input.readUInt32();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              storefiles_ = input.readUInt32();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              storeUncompressedSizeMB_ = input.readUInt32();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              storefileSizeMB_ = input.readUInt32();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              memstoreSizeMB_ = input.readUInt32();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              storefileIndexSizeMB_ = input.readUInt32();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              readRequestsCount_ = input.readUInt64();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              writeRequestsCount_ = input.readUInt64();
              break;
            }
            case 80: {
              bitField0_ |= 0x00000200;
              totalCompactingKVs_ = input.readUInt64();
              break;
            }
            case 88: {
              bitField0_ |= 0x00000400;
              currentCompactedKVs_ = input.readUInt64();
              break;
            }
            case 96: {
              bitField0_ |= 0x00000800;
              rootIndexSizeKB_ = input.readUInt32();
              break;
            }
            case 104: {
              bitField0_ |= 0x00001000;
              totalStaticIndexSizeKB_ = input.readUInt32();
              break;
            }
            case 112: {
              bitField0_ |= 0x00002000;
              totalStaticBloomSizeKB_ = input.readUInt32();
              break;
            }
            case 120: {
              bitField0_ |= 0x00004000;
              completeSequenceId_ = input.readUInt64();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionSpecifier region_specifier = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier regionSpecifier_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionSpecifierBuilder_;
      public boolean hasRegionSpecifier() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegionSpecifier() {
        if (regionSpecifierBuilder_ == null) {
          return regionSpecifier_;
        } else {
          return regionSpecifierBuilder_.getMessage();
        }
      }
      public Builder setRegionSpecifier(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionSpecifierBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionSpecifier_ = value;
          onChanged();
        } else {
          regionSpecifierBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegionSpecifier(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionSpecifierBuilder_ == null) {
          regionSpecifier_ = builderForValue.build();
          onChanged();
        } else {
          regionSpecifierBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegionSpecifier(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionSpecifierBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              regionSpecifier_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            regionSpecifier_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(regionSpecifier_).mergeFrom(value).buildPartial();
          } else {
            regionSpecifier_ = value;
          }
          onChanged();
        } else {
          regionSpecifierBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegionSpecifier() {
        if (regionSpecifierBuilder_ == null) {
          regionSpecifier_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionSpecifierBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionSpecifierBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionSpecifierFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionSpecifierOrBuilder() {
        if (regionSpecifierBuilder_ != null) {
          return regionSpecifierBuilder_.getMessageOrBuilder();
        } else {
          return regionSpecifier_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionSpecifierFieldBuilder() {
        if (regionSpecifierBuilder_ == null) {
          regionSpecifierBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  regionSpecifier_,
                  getParentForChildren(),
                  isClean());
          regionSpecifier_ = null;
        }
        return regionSpecifierBuilder_;
      }
      
      // optional uint32 stores = 2;
      private int stores_ ;
      public boolean hasStores() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public int getStores() {
        return stores_;
      }
      public Builder setStores(int value) {
        bitField0_ |= 0x00000002;
        stores_ = value;
        onChanged();
        return this;
      }
      public Builder clearStores() {
        bitField0_ = (bitField0_ & ~0x00000002);
        stores_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 storefiles = 3;
      private int storefiles_ ;
      public boolean hasStorefiles() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public int getStorefiles() {
        return storefiles_;
      }
      public Builder setStorefiles(int value) {
        bitField0_ |= 0x00000004;
        storefiles_ = value;
        onChanged();
        return this;
      }
      public Builder clearStorefiles() {
        bitField0_ = (bitField0_ & ~0x00000004);
        storefiles_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 store_uncompressed_size_MB = 4;
      private int storeUncompressedSizeMB_ ;
      public boolean hasStoreUncompressedSizeMB() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public int getStoreUncompressedSizeMB() {
        return storeUncompressedSizeMB_;
      }
      public Builder setStoreUncompressedSizeMB(int value) {
        bitField0_ |= 0x00000008;
        storeUncompressedSizeMB_ = value;
        onChanged();
        return this;
      }
      public Builder clearStoreUncompressedSizeMB() {
        bitField0_ = (bitField0_ & ~0x00000008);
        storeUncompressedSizeMB_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 storefile_size_MB = 5;
      private int storefileSizeMB_ ;
      public boolean hasStorefileSizeMB() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      public int getStorefileSizeMB() {
        return storefileSizeMB_;
      }
      public Builder setStorefileSizeMB(int value) {
        bitField0_ |= 0x00000010;
        storefileSizeMB_ = value;
        onChanged();
        return this;
      }
      public Builder clearStorefileSizeMB() {
        bitField0_ = (bitField0_ & ~0x00000010);
        storefileSizeMB_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 memstore_size_MB = 6;
      private int memstoreSizeMB_ ;
      public boolean hasMemstoreSizeMB() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      public int getMemstoreSizeMB() {
        return memstoreSizeMB_;
      }
      public Builder setMemstoreSizeMB(int value) {
        bitField0_ |= 0x00000020;
        memstoreSizeMB_ = value;
        onChanged();
        return this;
      }
      public Builder clearMemstoreSizeMB() {
        bitField0_ = (bitField0_ & ~0x00000020);
        memstoreSizeMB_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 storefile_index_size_MB = 7;
      private int storefileIndexSizeMB_ ;
      public boolean hasStorefileIndexSizeMB() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      public int getStorefileIndexSizeMB() {
        return storefileIndexSizeMB_;
      }
      public Builder setStorefileIndexSizeMB(int value) {
        bitField0_ |= 0x00000040;
        storefileIndexSizeMB_ = value;
        onChanged();
        return this;
      }
      public Builder clearStorefileIndexSizeMB() {
        bitField0_ = (bitField0_ & ~0x00000040);
        storefileIndexSizeMB_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint64 read_requests_count = 8;
      private long readRequestsCount_ ;
      public boolean hasReadRequestsCount() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      public long getReadRequestsCount() {
        return readRequestsCount_;
      }
      public Builder setReadRequestsCount(long value) {
        bitField0_ |= 0x00000080;
        readRequestsCount_ = value;
        onChanged();
        return this;
      }
      public Builder clearReadRequestsCount() {
        bitField0_ = (bitField0_ & ~0x00000080);
        readRequestsCount_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint64 write_requests_count = 9;
      private long writeRequestsCount_ ;
      public boolean hasWriteRequestsCount() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      public long getWriteRequestsCount() {
        return writeRequestsCount_;
      }
      public Builder setWriteRequestsCount(long value) {
        bitField0_ |= 0x00000100;
        writeRequestsCount_ = value;
        onChanged();
        return this;
      }
      public Builder clearWriteRequestsCount() {
        bitField0_ = (bitField0_ & ~0x00000100);
        writeRequestsCount_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint64 total_compacting_KVs = 10;
      private long totalCompactingKVs_ ;
      public boolean hasTotalCompactingKVs() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      public long getTotalCompactingKVs() {
        return totalCompactingKVs_;
      }
      public Builder setTotalCompactingKVs(long value) {
        bitField0_ |= 0x00000200;
        totalCompactingKVs_ = value;
        onChanged();
        return this;
      }
      public Builder clearTotalCompactingKVs() {
        bitField0_ = (bitField0_ & ~0x00000200);
        totalCompactingKVs_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint64 current_compacted_KVs = 11;
      private long currentCompactedKVs_ ;
      public boolean hasCurrentCompactedKVs() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      public long getCurrentCompactedKVs() {
        return currentCompactedKVs_;
      }
      public Builder setCurrentCompactedKVs(long value) {
        bitField0_ |= 0x00000400;
        currentCompactedKVs_ = value;
        onChanged();
        return this;
      }
      public Builder clearCurrentCompactedKVs() {
        bitField0_ = (bitField0_ & ~0x00000400);
        currentCompactedKVs_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint32 root_index_size_KB = 12;
      private int rootIndexSizeKB_ ;
      public boolean hasRootIndexSizeKB() {
        return ((bitField0_ & 0x00000800) == 0x00000800);
      }
      public int getRootIndexSizeKB() {
        return rootIndexSizeKB_;
      }
      public Builder setRootIndexSizeKB(int value) {
        bitField0_ |= 0x00000800;
        rootIndexSizeKB_ = value;
        onChanged();
        return this;
      }
      public Builder clearRootIndexSizeKB() {
        bitField0_ = (bitField0_ & ~0x00000800);
        rootIndexSizeKB_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 total_static_index_size_KB = 13;
      private int totalStaticIndexSizeKB_ ;
      public boolean hasTotalStaticIndexSizeKB() {
        return ((bitField0_ & 0x00001000) == 0x00001000);
      }
      public int getTotalStaticIndexSizeKB() {
        return totalStaticIndexSizeKB_;
      }
      public Builder setTotalStaticIndexSizeKB(int value) {
        bitField0_ |= 0x00001000;
        totalStaticIndexSizeKB_ = value;
        onChanged();
        return this;
      }
      public Builder clearTotalStaticIndexSizeKB() {
        bitField0_ = (bitField0_ & ~0x00001000);
        totalStaticIndexSizeKB_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 total_static_bloom_size_KB = 14;
      private int totalStaticBloomSizeKB_ ;
      public boolean hasTotalStaticBloomSizeKB() {
        return ((bitField0_ & 0x00002000) == 0x00002000);
      }
      public int getTotalStaticBloomSizeKB() {
        return totalStaticBloomSizeKB_;
      }
      public Builder setTotalStaticBloomSizeKB(int value) {
        bitField0_ |= 0x00002000;
        totalStaticBloomSizeKB_ = value;
        onChanged();
        return this;
      }
      public Builder clearTotalStaticBloomSizeKB() {
        bitField0_ = (bitField0_ & ~0x00002000);
        totalStaticBloomSizeKB_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint64 complete_sequence_id = 15;
      private long completeSequenceId_ ;
      public boolean hasCompleteSequenceId() {
        return ((bitField0_ & 0x00004000) == 0x00004000);
      }
      public long getCompleteSequenceId() {
        return completeSequenceId_;
      }
      public Builder setCompleteSequenceId(long value) {
        bitField0_ |= 0x00004000;
        completeSequenceId_ = value;
        onChanged();
        return this;
      }
      public Builder clearCompleteSequenceId() {
        bitField0_ = (bitField0_ & ~0x00004000);
        completeSequenceId_ = 0L;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:RegionLoad)
    }
    
    static {
      defaultInstance = new RegionLoad(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:RegionLoad)
  }
  
  public interface ServerLoadOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional uint32 number_of_requests = 1;
    boolean hasNumberOfRequests();
    int getNumberOfRequests();
    
    // optional uint32 total_number_of_requests = 2;
    boolean hasTotalNumberOfRequests();
    int getTotalNumberOfRequests();
    
    // optional uint32 used_heap_MB = 3;
    boolean hasUsedHeapMB();
    int getUsedHeapMB();
    
    // optional uint32 max_heap_MB = 4;
    boolean hasMaxHeapMB();
    int getMaxHeapMB();
    
    // repeated .RegionLoad region_loads = 5;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad> 
        getRegionLoadsList();
    org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad getRegionLoads(int index);
    int getRegionLoadsCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder> 
        getRegionLoadsOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder getRegionLoadsOrBuilder(
        int index);
    
    // repeated .Coprocessor coprocessors = 6;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> 
        getCoprocessorsList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor getCoprocessors(int index);
    int getCoprocessorsCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
        getCoprocessorsOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder getCoprocessorsOrBuilder(
        int index);
    
    // optional uint64 report_start_time = 7;
    boolean hasReportStartTime();
    long getReportStartTime();
    
    // optional uint64 report_end_time = 8;
    boolean hasReportEndTime();
    long getReportEndTime();
    
    // optional uint32 info_server_port = 9;
    boolean hasInfoServerPort();
    int getInfoServerPort();
  }
  public static final class ServerLoad extends
      com.google.protobuf.GeneratedMessage
      implements ServerLoadOrBuilder {
    // Use ServerLoad.newBuilder() to construct.
    private ServerLoad(Builder builder) {
      super(builder);
    }
    private ServerLoad(boolean noInit) {}
    
    private static final ServerLoad defaultInstance;
    public static ServerLoad getDefaultInstance() {
      return defaultInstance;
    }
    
    public ServerLoad getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_ServerLoad_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_ServerLoad_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional uint32 number_of_requests = 1;
    public static final int NUMBER_OF_REQUESTS_FIELD_NUMBER = 1;
    private int numberOfRequests_;
    public boolean hasNumberOfRequests() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public int getNumberOfRequests() {
      return numberOfRequests_;
    }
    
    // optional uint32 total_number_of_requests = 2;
    public static final int TOTAL_NUMBER_OF_REQUESTS_FIELD_NUMBER = 2;
    private int totalNumberOfRequests_;
    public boolean hasTotalNumberOfRequests() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public int getTotalNumberOfRequests() {
      return totalNumberOfRequests_;
    }
    
    // optional uint32 used_heap_MB = 3;
    public static final int USED_HEAP_MB_FIELD_NUMBER = 3;
    private int usedHeapMB_;
    public boolean hasUsedHeapMB() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public int getUsedHeapMB() {
      return usedHeapMB_;
    }
    
    // optional uint32 max_heap_MB = 4;
    public static final int MAX_HEAP_MB_FIELD_NUMBER = 4;
    private int maxHeapMB_;
    public boolean hasMaxHeapMB() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public int getMaxHeapMB() {
      return maxHeapMB_;
    }
    
    // repeated .RegionLoad region_loads = 5;
    public static final int REGION_LOADS_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad> regionLoads_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad> getRegionLoadsList() {
      return regionLoads_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder> 
        getRegionLoadsOrBuilderList() {
      return regionLoads_;
    }
    public int getRegionLoadsCount() {
      return regionLoads_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad getRegionLoads(int index) {
      return regionLoads_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder getRegionLoadsOrBuilder(
        int index) {
      return regionLoads_.get(index);
    }
    
    // repeated .Coprocessor coprocessors = 6;
    public static final int COPROCESSORS_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> coprocessors_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> getCoprocessorsList() {
      return coprocessors_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
        getCoprocessorsOrBuilderList() {
      return coprocessors_;
    }
    public int getCoprocessorsCount() {
      return coprocessors_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor getCoprocessors(int index) {
      return coprocessors_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder getCoprocessorsOrBuilder(
        int index) {
      return coprocessors_.get(index);
    }
    
    // optional uint64 report_start_time = 7;
    public static final int REPORT_START_TIME_FIELD_NUMBER = 7;
    private long reportStartTime_;
    public boolean hasReportStartTime() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    public long getReportStartTime() {
      return reportStartTime_;
    }
    
    // optional uint64 report_end_time = 8;
    public static final int REPORT_END_TIME_FIELD_NUMBER = 8;
    private long reportEndTime_;
    public boolean hasReportEndTime() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    public long getReportEndTime() {
      return reportEndTime_;
    }
    
    // optional uint32 info_server_port = 9;
    public static final int INFO_SERVER_PORT_FIELD_NUMBER = 9;
    private int infoServerPort_;
    public boolean hasInfoServerPort() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    public int getInfoServerPort() {
      return infoServerPort_;
    }
    
    private void initFields() {
      numberOfRequests_ = 0;
      totalNumberOfRequests_ = 0;
      usedHeapMB_ = 0;
      maxHeapMB_ = 0;
      regionLoads_ = java.util.Collections.emptyList();
      coprocessors_ = java.util.Collections.emptyList();
      reportStartTime_ = 0L;
      reportEndTime_ = 0L;
      infoServerPort_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      for (int i = 0; i < getRegionLoadsCount(); i++) {
        if (!getRegionLoads(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getCoprocessorsCount(); i++) {
        if (!getCoprocessors(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt32(1, numberOfRequests_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt32(2, totalNumberOfRequests_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt32(3, usedHeapMB_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt32(4, maxHeapMB_);
      }
      for (int i = 0; i < regionLoads_.size(); i++) {
        output.writeMessage(5, regionLoads_.get(i));
      }
      for (int i = 0; i < coprocessors_.size(); i++) {
        output.writeMessage(6, coprocessors_.get(i));
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeUInt64(7, reportStartTime_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeUInt64(8, reportEndTime_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeUInt32(9, infoServerPort_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(1, numberOfRequests_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, totalNumberOfRequests_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(3, usedHeapMB_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, maxHeapMB_);
      }
      for (int i = 0; i < regionLoads_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, regionLoads_.get(i));
      }
      for (int i = 0; i < coprocessors_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, coprocessors_.get(i));
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(7, reportStartTime_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(8, reportEndTime_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(9, infoServerPort_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad other = (org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad) obj;
      
      boolean result = true;
      result = result && (hasNumberOfRequests() == other.hasNumberOfRequests());
      if (hasNumberOfRequests()) {
        result = result && (getNumberOfRequests()
            == other.getNumberOfRequests());
      }
      result = result && (hasTotalNumberOfRequests() == other.hasTotalNumberOfRequests());
      if (hasTotalNumberOfRequests()) {
        result = result && (getTotalNumberOfRequests()
            == other.getTotalNumberOfRequests());
      }
      result = result && (hasUsedHeapMB() == other.hasUsedHeapMB());
      if (hasUsedHeapMB()) {
        result = result && (getUsedHeapMB()
            == other.getUsedHeapMB());
      }
      result = result && (hasMaxHeapMB() == other.hasMaxHeapMB());
      if (hasMaxHeapMB()) {
        result = result && (getMaxHeapMB()
            == other.getMaxHeapMB());
      }
      result = result && getRegionLoadsList()
          .equals(other.getRegionLoadsList());
      result = result && getCoprocessorsList()
          .equals(other.getCoprocessorsList());
      result = result && (hasReportStartTime() == other.hasReportStartTime());
      if (hasReportStartTime()) {
        result = result && (getReportStartTime()
            == other.getReportStartTime());
      }
      result = result && (hasReportEndTime() == other.hasReportEndTime());
      if (hasReportEndTime()) {
        result = result && (getReportEndTime()
            == other.getReportEndTime());
      }
      result = result && (hasInfoServerPort() == other.hasInfoServerPort());
      if (hasInfoServerPort()) {
        result = result && (getInfoServerPort()
            == other.getInfoServerPort());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNumberOfRequests()) {
        hash = (37 * hash) + NUMBER_OF_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getNumberOfRequests();
      }
      if (hasTotalNumberOfRequests()) {
        hash = (37 * hash) + TOTAL_NUMBER_OF_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getTotalNumberOfRequests();
      }
      if (hasUsedHeapMB()) {
        hash = (37 * hash) + USED_HEAP_MB_FIELD_NUMBER;
        hash = (53 * hash) + getUsedHeapMB();
      }
      if (hasMaxHeapMB()) {
        hash = (37 * hash) + MAX_HEAP_MB_FIELD_NUMBER;
        hash = (53 * hash) + getMaxHeapMB();
      }
      if (getRegionLoadsCount() > 0) {
        hash = (37 * hash) + REGION_LOADS_FIELD_NUMBER;
        hash = (53 * hash) + getRegionLoadsList().hashCode();
      }
      if (getCoprocessorsCount() > 0) {
        hash = (37 * hash) + COPROCESSORS_FIELD_NUMBER;
        hash = (53 * hash) + getCoprocessorsList().hashCode();
      }
      if (hasReportStartTime()) {
        hash = (37 * hash) + REPORT_START_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getReportStartTime());
      }
      if (hasReportEndTime()) {
        hash = (37 * hash) + REPORT_END_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getReportEndTime());
      }
      if (hasInfoServerPort()) {
        hash = (37 * hash) + INFO_SERVER_PORT_FIELD_NUMBER;
        hash = (53 * hash) + getInfoServerPort();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoadOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_ServerLoad_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_ServerLoad_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionLoadsFieldBuilder();
          getCoprocessorsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        numberOfRequests_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        totalNumberOfRequests_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        usedHeapMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        maxHeapMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (regionLoadsBuilder_ == null) {
          regionLoads_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          regionLoadsBuilder_.clear();
        }
        if (coprocessorsBuilder_ == null) {
          coprocessors_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          coprocessorsBuilder_.clear();
        }
        reportStartTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000040);
        reportEndTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000080);
        infoServerPort_ = 0;
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad build() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad result = new org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.numberOfRequests_ = numberOfRequests_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.totalNumberOfRequests_ = totalNumberOfRequests_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.usedHeapMB_ = usedHeapMB_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.maxHeapMB_ = maxHeapMB_;
        if (regionLoadsBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            regionLoads_ = java.util.Collections.unmodifiableList(regionLoads_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.regionLoads_ = regionLoads_;
        } else {
          result.regionLoads_ = regionLoadsBuilder_.build();
        }
        if (coprocessorsBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            coprocessors_ = java.util.Collections.unmodifiableList(coprocessors_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.coprocessors_ = coprocessors_;
        } else {
          result.coprocessors_ = coprocessorsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000010;
        }
        result.reportStartTime_ = reportStartTime_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000020;
        }
        result.reportEndTime_ = reportEndTime_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000040;
        }
        result.infoServerPort_ = infoServerPort_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.getDefaultInstance()) return this;
        if (other.hasNumberOfRequests()) {
          setNumberOfRequests(other.getNumberOfRequests());
        }
        if (other.hasTotalNumberOfRequests()) {
          setTotalNumberOfRequests(other.getTotalNumberOfRequests());
        }
        if (other.hasUsedHeapMB()) {
          setUsedHeapMB(other.getUsedHeapMB());
        }
        if (other.hasMaxHeapMB()) {
          setMaxHeapMB(other.getMaxHeapMB());
        }
        if (regionLoadsBuilder_ == null) {
          if (!other.regionLoads_.isEmpty()) {
            if (regionLoads_.isEmpty()) {
              regionLoads_ = other.regionLoads_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureRegionLoadsIsMutable();
              regionLoads_.addAll(other.regionLoads_);
            }
            onChanged();
          }
        } else {
          if (!other.regionLoads_.isEmpty()) {
            if (regionLoadsBuilder_.isEmpty()) {
              regionLoadsBuilder_.dispose();
              regionLoadsBuilder_ = null;
              regionLoads_ = other.regionLoads_;
              bitField0_ = (bitField0_ & ~0x00000010);
              regionLoadsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getRegionLoadsFieldBuilder() : null;
            } else {
              regionLoadsBuilder_.addAllMessages(other.regionLoads_);
            }
          }
        }
        if (coprocessorsBuilder_ == null) {
          if (!other.coprocessors_.isEmpty()) {
            if (coprocessors_.isEmpty()) {
              coprocessors_ = other.coprocessors_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureCoprocessorsIsMutable();
              coprocessors_.addAll(other.coprocessors_);
            }
            onChanged();
          }
        } else {
          if (!other.coprocessors_.isEmpty()) {
            if (coprocessorsBuilder_.isEmpty()) {
              coprocessorsBuilder_.dispose();
              coprocessorsBuilder_ = null;
              coprocessors_ = other.coprocessors_;
              bitField0_ = (bitField0_ & ~0x00000020);
              coprocessorsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getCoprocessorsFieldBuilder() : null;
            } else {
              coprocessorsBuilder_.addAllMessages(other.coprocessors_);
            }
          }
        }
        if (other.hasReportStartTime()) {
          setReportStartTime(other.getReportStartTime());
        }
        if (other.hasReportEndTime()) {
          setReportEndTime(other.getReportEndTime());
        }
        if (other.hasInfoServerPort()) {
          setInfoServerPort(other.getInfoServerPort());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        for (int i = 0; i < getRegionLoadsCount(); i++) {
          if (!getRegionLoads(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getCoprocessorsCount(); i++) {
          if (!getCoprocessors(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              numberOfRequests_ = input.readUInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              totalNumberOfRequests_ = input.readUInt32();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              usedHeapMB_ = input.readUInt32();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              maxHeapMB_ = input.readUInt32();
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addRegionLoads(subBuilder.buildPartial());
              break;
            }
            case 50: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addCoprocessors(subBuilder.buildPartial());
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              reportStartTime_ = input.readUInt64();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              reportEndTime_ = input.readUInt64();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              infoServerPort_ = input.readUInt32();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional uint32 number_of_requests = 1;
      private int numberOfRequests_ ;
      public boolean hasNumberOfRequests() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public int getNumberOfRequests() {
        return numberOfRequests_;
      }
      public Builder setNumberOfRequests(int value) {
        bitField0_ |= 0x00000001;
        numberOfRequests_ = value;
        onChanged();
        return this;
      }
      public Builder clearNumberOfRequests() {
        bitField0_ = (bitField0_ & ~0x00000001);
        numberOfRequests_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 total_number_of_requests = 2;
      private int totalNumberOfRequests_ ;
      public boolean hasTotalNumberOfRequests() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public int getTotalNumberOfRequests() {
        return totalNumberOfRequests_;
      }
      public Builder setTotalNumberOfRequests(int value) {
        bitField0_ |= 0x00000002;
        totalNumberOfRequests_ = value;
        onChanged();
        return this;
      }
      public Builder clearTotalNumberOfRequests() {
        bitField0_ = (bitField0_ & ~0x00000002);
        totalNumberOfRequests_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 used_heap_MB = 3;
      private int usedHeapMB_ ;
      public boolean hasUsedHeapMB() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public int getUsedHeapMB() {
        return usedHeapMB_;
      }
      public Builder setUsedHeapMB(int value) {
        bitField0_ |= 0x00000004;
        usedHeapMB_ = value;
        onChanged();
        return this;
      }
      public Builder clearUsedHeapMB() {
        bitField0_ = (bitField0_ & ~0x00000004);
        usedHeapMB_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 max_heap_MB = 4;
      private int maxHeapMB_ ;
      public boolean hasMaxHeapMB() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public int getMaxHeapMB() {
        return maxHeapMB_;
      }
      public Builder setMaxHeapMB(int value) {
        bitField0_ |= 0x00000008;
        maxHeapMB_ = value;
        onChanged();
        return this;
      }
      public Builder clearMaxHeapMB() {
        bitField0_ = (bitField0_ & ~0x00000008);
        maxHeapMB_ = 0;
        onChanged();
        return this;
      }
      
      // repeated .RegionLoad region_loads = 5;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad> regionLoads_ =
        java.util.Collections.emptyList();
      private void ensureRegionLoadsIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          regionLoads_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad>(regionLoads_);
          bitField0_ |= 0x00000010;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder> regionLoadsBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad> getRegionLoadsList() {
        if (regionLoadsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionLoads_);
        } else {
          return regionLoadsBuilder_.getMessageList();
        }
      }
      public int getRegionLoadsCount() {
        if (regionLoadsBuilder_ == null) {
          return regionLoads_.size();
        } else {
          return regionLoadsBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad getRegionLoads(int index) {
        if (regionLoadsBuilder_ == null) {
          return regionLoads_.get(index);
        } else {
          return regionLoadsBuilder_.getMessage(index);
        }
      }
      public Builder setRegionLoads(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad value) {
        if (regionLoadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionLoadsIsMutable();
          regionLoads_.set(index, value);
          onChanged();
        } else {
          regionLoadsBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setRegionLoads(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder builderForValue) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionLoadsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addRegionLoads(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad value) {
        if (regionLoadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionLoadsIsMutable();
          regionLoads_.add(value);
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addRegionLoads(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad value) {
        if (regionLoadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionLoadsIsMutable();
          regionLoads_.add(index, value);
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addRegionLoads(
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder builderForValue) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.add(builderForValue.build());
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addRegionLoads(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder builderForValue) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllRegionLoads(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad> values) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          super.addAll(values, regionLoads_);
          onChanged();
        } else {
          regionLoadsBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearRegionLoads() {
        if (regionLoadsBuilder_ == null) {
          regionLoads_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          regionLoadsBuilder_.clear();
        }
        return this;
      }
      public Builder removeRegionLoads(int index) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.remove(index);
          onChanged();
        } else {
          regionLoadsBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder getRegionLoadsBuilder(
          int index) {
        return getRegionLoadsFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder getRegionLoadsOrBuilder(
          int index) {
        if (regionLoadsBuilder_ == null) {
          return regionLoads_.get(index);  } else {
          return regionLoadsBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder> 
           getRegionLoadsOrBuilderList() {
        if (regionLoadsBuilder_ != null) {
          return regionLoadsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionLoads_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder addRegionLoadsBuilder() {
        return getRegionLoadsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder addRegionLoadsBuilder(
          int index) {
        return getRegionLoadsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder> 
           getRegionLoadsBuilderList() {
        return getRegionLoadsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder> 
          getRegionLoadsFieldBuilder() {
        if (regionLoadsBuilder_ == null) {
          regionLoadsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoadOrBuilder>(
                  regionLoads_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          regionLoads_ = null;
        }
        return regionLoadsBuilder_;
      }
      
      // repeated .Coprocessor coprocessors = 6;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> coprocessors_ =
        java.util.Collections.emptyList();
      private void ensureCoprocessorsIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          coprocessors_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor>(coprocessors_);
          bitField0_ |= 0x00000020;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> coprocessorsBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> getCoprocessorsList() {
        if (coprocessorsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(coprocessors_);
        } else {
          return coprocessorsBuilder_.getMessageList();
        }
      }
      public int getCoprocessorsCount() {
        if (coprocessorsBuilder_ == null) {
          return coprocessors_.size();
        } else {
          return coprocessorsBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor getCoprocessors(int index) {
        if (coprocessorsBuilder_ == null) {
          return coprocessors_.get(index);
        } else {
          return coprocessorsBuilder_.getMessage(index);
        }
      }
      public Builder setCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor value) {
        if (coprocessorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCoprocessorsIsMutable();
          coprocessors_.set(index, value);
          onChanged();
        } else {
          coprocessorsBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder builderForValue) {
        if (coprocessorsBuilder_ == null) {
          ensureCoprocessorsIsMutable();
          coprocessors_.set(index, builderForValue.build());
          onChanged();
        } else {
          coprocessorsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addCoprocessors(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor value) {
        if (coprocessorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCoprocessorsIsMutable();
          coprocessors_.add(value);
          onChanged();
        } else {
          coprocessorsBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor value) {
        if (coprocessorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCoprocessorsIsMutable();
          coprocessors_.add(index, value);
          onChanged();
        } else {
          coprocessorsBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addCoprocessors(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder builderForValue) {
        if (coprocessorsBuilder_ == null) {
          ensureCoprocessorsIsMutable();
          coprocessors_.add(builderForValue.build());
          onChanged();
        } else {
          coprocessorsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder builderForValue) {
        if (coprocessorsBuilder_ == null) {
          ensureCoprocessorsIsMutable();
          coprocessors_.add(index, builderForValue.build());
          onChanged();
        } else {
          coprocessorsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllCoprocessors(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> values) {
        if (coprocessorsBuilder_ == null) {
          ensureCoprocessorsIsMutable();
          super.addAll(values, coprocessors_);
          onChanged();
        } else {
          coprocessorsBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearCoprocessors() {
        if (coprocessorsBuilder_ == null) {
          coprocessors_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          coprocessorsBuilder_.clear();
        }
        return this;
      }
      public Builder removeCoprocessors(int index) {
        if (coprocessorsBuilder_ == null) {
          ensureCoprocessorsIsMutable();
          coprocessors_.remove(index);
          onChanged();
        } else {
          coprocessorsBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder getCoprocessorsBuilder(
          int index) {
        return getCoprocessorsFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder getCoprocessorsOrBuilder(
          int index) {
        if (coprocessorsBuilder_ == null) {
          return coprocessors_.get(index);  } else {
          return coprocessorsBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
           getCoprocessorsOrBuilderList() {
        if (coprocessorsBuilder_ != null) {
          return coprocessorsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(coprocessors_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder addCoprocessorsBuilder() {
        return getCoprocessorsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder addCoprocessorsBuilder(
          int index) {
        return getCoprocessorsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder> 
           getCoprocessorsBuilderList() {
        return getCoprocessorsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
          getCoprocessorsFieldBuilder() {
        if (coprocessorsBuilder_ == null) {
          coprocessorsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder>(
                  coprocessors_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          coprocessors_ = null;
        }
        return coprocessorsBuilder_;
      }
      
      // optional uint64 report_start_time = 7;
      private long reportStartTime_ ;
      public boolean hasReportStartTime() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      public long getReportStartTime() {
        return reportStartTime_;
      }
      public Builder setReportStartTime(long value) {
        bitField0_ |= 0x00000040;
        reportStartTime_ = value;
        onChanged();
        return this;
      }
      public Builder clearReportStartTime() {
        bitField0_ = (bitField0_ & ~0x00000040);
        reportStartTime_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint64 report_end_time = 8;
      private long reportEndTime_ ;
      public boolean hasReportEndTime() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      public long getReportEndTime() {
        return reportEndTime_;
      }
      public Builder setReportEndTime(long value) {
        bitField0_ |= 0x00000080;
        reportEndTime_ = value;
        onChanged();
        return this;
      }
      public Builder clearReportEndTime() {
        bitField0_ = (bitField0_ & ~0x00000080);
        reportEndTime_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint32 info_server_port = 9;
      private int infoServerPort_ ;
      public boolean hasInfoServerPort() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      public int getInfoServerPort() {
        return infoServerPort_;
      }
      public Builder setInfoServerPort(int value) {
        bitField0_ |= 0x00000100;
        infoServerPort_ = value;
        onChanged();
        return this;
      }
      public Builder clearInfoServerPort() {
        bitField0_ = (bitField0_ & ~0x00000100);
        infoServerPort_ = 0;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:ServerLoad)
    }
    
    static {
      defaultInstance = new ServerLoad(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:ServerLoad)
  }
  
  public interface LiveServerInfoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .ServerName server = 1;
    boolean hasServer();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getServer();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerOrBuilder();
    
    // required .ServerLoad server_load = 2;
    boolean hasServerLoad();
    org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad getServerLoad();
    org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoadOrBuilder getServerLoadOrBuilder();
  }
  public static final class LiveServerInfo extends
      com.google.protobuf.GeneratedMessage
      implements LiveServerInfoOrBuilder {
    // Use LiveServerInfo.newBuilder() to construct.
    private LiveServerInfo(Builder builder) {
      super(builder);
    }
    private LiveServerInfo(boolean noInit) {}
    
    private static final LiveServerInfo defaultInstance;
    public static LiveServerInfo getDefaultInstance() {
      return defaultInstance;
    }
    
    public LiveServerInfo getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_LiveServerInfo_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_LiveServerInfo_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .ServerName server = 1;
    public static final int SERVER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName server_;
    public boolean hasServer() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getServer() {
      return server_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerOrBuilder() {
      return server_;
    }
    
    // required .ServerLoad server_load = 2;
    public static final int SERVER_LOAD_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad serverLoad_;
    public boolean hasServerLoad() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad getServerLoad() {
      return serverLoad_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoadOrBuilder getServerLoadOrBuilder() {
      return serverLoad_;
    }
    
    private void initFields() {
      server_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
      serverLoad_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasServer()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasServerLoad()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getServer().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getServerLoad().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, server_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, serverLoad_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, server_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, serverLoad_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo other = (org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo) obj;
      
      boolean result = true;
      result = result && (hasServer() == other.hasServer());
      if (hasServer()) {
        result = result && getServer()
            .equals(other.getServer());
      }
      result = result && (hasServerLoad() == other.hasServerLoad());
      if (hasServerLoad()) {
        result = result && getServerLoad()
            .equals(other.getServerLoad());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasServer()) {
        hash = (37 * hash) + SERVER_FIELD_NUMBER;
        hash = (53 * hash) + getServer().hashCode();
      }
      if (hasServerLoad()) {
        hash = (37 * hash) + SERVER_LOAD_FIELD_NUMBER;
        hash = (53 * hash) + getServerLoad().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_LiveServerInfo_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_LiveServerInfo_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getServerFieldBuilder();
          getServerLoadFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (serverBuilder_ == null) {
          server_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
        } else {
          serverBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (serverLoadBuilder_ == null) {
          serverLoad_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.getDefaultInstance();
        } else {
          serverLoadBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo build() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo result = new org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (serverBuilder_ == null) {
          result.server_ = server_;
        } else {
          result.server_ = serverBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (serverLoadBuilder_ == null) {
          result.serverLoad_ = serverLoad_;
        } else {
          result.serverLoad_ = serverLoadBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.getDefaultInstance()) return this;
        if (other.hasServer()) {
          mergeServer(other.getServer());
        }
        if (other.hasServerLoad()) {
          mergeServerLoad(other.getServerLoad());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasServer()) {
          
          return false;
        }
        if (!hasServerLoad()) {
          
          return false;
        }
        if (!getServer().isInitialized()) {
          
          return false;
        }
        if (!getServerLoad().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.newBuilder();
              if (hasServer()) {
                subBuilder.mergeFrom(getServer());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setServer(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.newBuilder();
              if (hasServerLoad()) {
                subBuilder.mergeFrom(getServerLoad());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setServerLoad(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .ServerName server = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName server_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> serverBuilder_;
      public boolean hasServer() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getServer() {
        if (serverBuilder_ == null) {
          return server_;
        } else {
          return serverBuilder_.getMessage();
        }
      }
      public Builder setServer(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          server_ = value;
          onChanged();
        } else {
          serverBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setServer(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (serverBuilder_ == null) {
          server_ = builderForValue.build();
          onChanged();
        } else {
          serverBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeServer(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (serverBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              server_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            server_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.newBuilder(server_).mergeFrom(value).buildPartial();
          } else {
            server_ = value;
          }
          onChanged();
        } else {
          serverBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearServer() {
        if (serverBuilder_ == null) {
          server_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
          onChanged();
        } else {
          serverBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder getServerBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getServerFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getServerOrBuilder() {
        if (serverBuilder_ != null) {
          return serverBuilder_.getMessageOrBuilder();
        } else {
          return server_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getServerFieldBuilder() {
        if (serverBuilder_ == null) {
          serverBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  server_,
                  getParentForChildren(),
                  isClean());
          server_ = null;
        }
        return serverBuilder_;
      }
      
      // required .ServerLoad server_load = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad serverLoad_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoadOrBuilder> serverLoadBuilder_;
      public boolean hasServerLoad() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad getServerLoad() {
        if (serverLoadBuilder_ == null) {
          return serverLoad_;
        } else {
          return serverLoadBuilder_.getMessage();
        }
      }
      public Builder setServerLoad(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad value) {
        if (serverLoadBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          serverLoad_ = value;
          onChanged();
        } else {
          serverLoadBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setServerLoad(
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.Builder builderForValue) {
        if (serverLoadBuilder_ == null) {
          serverLoad_ = builderForValue.build();
          onChanged();
        } else {
          serverLoadBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeServerLoad(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad value) {
        if (serverLoadBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              serverLoad_ != org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.getDefaultInstance()) {
            serverLoad_ =
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.newBuilder(serverLoad_).mergeFrom(value).buildPartial();
          } else {
            serverLoad_ = value;
          }
          onChanged();
        } else {
          serverLoadBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearServerLoad() {
        if (serverLoadBuilder_ == null) {
          serverLoad_ = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.getDefaultInstance();
          onChanged();
        } else {
          serverLoadBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.Builder getServerLoadBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getServerLoadFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoadOrBuilder getServerLoadOrBuilder() {
        if (serverLoadBuilder_ != null) {
          return serverLoadBuilder_.getMessageOrBuilder();
        } else {
          return serverLoad_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoadOrBuilder> 
          getServerLoadFieldBuilder() {
        if (serverLoadBuilder_ == null) {
          serverLoadBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoadOrBuilder>(
                  serverLoad_,
                  getParentForChildren(),
                  isClean());
          serverLoad_ = null;
        }
        return serverLoadBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:LiveServerInfo)
    }
    
    static {
      defaultInstance = new LiveServerInfo(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:LiveServerInfo)
  }
  
  public interface ClusterStatusOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .HBaseVersionFileContent hbase_version = 1;
    boolean hasHbaseVersion();
    org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent getHbaseVersion();
    org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContentOrBuilder getHbaseVersionOrBuilder();
    
    // repeated .LiveServerInfo live_servers = 2;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo> 
        getLiveServersList();
    org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo getLiveServers(int index);
    int getLiveServersCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfoOrBuilder> 
        getLiveServersOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfoOrBuilder getLiveServersOrBuilder(
        int index);
    
    // repeated .ServerName dead_servers = 3;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> 
        getDeadServersList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getDeadServers(int index);
    int getDeadServersCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
        getDeadServersOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDeadServersOrBuilder(
        int index);
    
    // repeated .RegionInTransition regions_in_transition = 4;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition> 
        getRegionsInTransitionList();
    org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition getRegionsInTransition(int index);
    int getRegionsInTransitionCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransitionOrBuilder> 
        getRegionsInTransitionOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransitionOrBuilder getRegionsInTransitionOrBuilder(
        int index);
    
    // optional .ClusterId cluster_id = 5;
    boolean hasClusterId();
    org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId getClusterId();
    org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterIdOrBuilder getClusterIdOrBuilder();
    
    // repeated .Coprocessor master_coprocessors = 6;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> 
        getMasterCoprocessorsList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor getMasterCoprocessors(int index);
    int getMasterCoprocessorsCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
        getMasterCoprocessorsOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder getMasterCoprocessorsOrBuilder(
        int index);
    
    // optional .ServerName master = 7;
    boolean hasMaster();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getMaster();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getMasterOrBuilder();
    
    // repeated .ServerName backup_masters = 8;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> 
        getBackupMastersList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getBackupMasters(int index);
    int getBackupMastersCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
        getBackupMastersOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getBackupMastersOrBuilder(
        int index);
    
    // optional bool balancer_on = 9;
    boolean hasBalancerOn();
    boolean getBalancerOn();
  }
  public static final class ClusterStatus extends
      com.google.protobuf.GeneratedMessage
      implements ClusterStatusOrBuilder {
    // Use ClusterStatus.newBuilder() to construct.
    private ClusterStatus(Builder builder) {
      super(builder);
    }
    private ClusterStatus(boolean noInit) {}
    
    private static final ClusterStatus defaultInstance;
    public static ClusterStatus getDefaultInstance() {
      return defaultInstance;
    }
    
    public ClusterStatus getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_ClusterStatus_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_ClusterStatus_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .HBaseVersionFileContent hbase_version = 1;
    public static final int HBASE_VERSION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent hbaseVersion_;
    public boolean hasHbaseVersion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent getHbaseVersion() {
      return hbaseVersion_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContentOrBuilder getHbaseVersionOrBuilder() {
      return hbaseVersion_;
    }
    
    // repeated .LiveServerInfo live_servers = 2;
    public static final int LIVE_SERVERS_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo> liveServers_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo> getLiveServersList() {
      return liveServers_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfoOrBuilder> 
        getLiveServersOrBuilderList() {
      return liveServers_;
    }
    public int getLiveServersCount() {
      return liveServers_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo getLiveServers(int index) {
      return liveServers_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfoOrBuilder getLiveServersOrBuilder(
        int index) {
      return liveServers_.get(index);
    }
    
    // repeated .ServerName dead_servers = 3;
    public static final int DEAD_SERVERS_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> deadServers_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> getDeadServersList() {
      return deadServers_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
        getDeadServersOrBuilderList() {
      return deadServers_;
    }
    public int getDeadServersCount() {
      return deadServers_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getDeadServers(int index) {
      return deadServers_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDeadServersOrBuilder(
        int index) {
      return deadServers_.get(index);
    }
    
    // repeated .RegionInTransition regions_in_transition = 4;
    public static final int REGIONS_IN_TRANSITION_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition> regionsInTransition_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition> getRegionsInTransitionList() {
      return regionsInTransition_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransitionOrBuilder> 
        getRegionsInTransitionOrBuilderList() {
      return regionsInTransition_;
    }
    public int getRegionsInTransitionCount() {
      return regionsInTransition_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition getRegionsInTransition(int index) {
      return regionsInTransition_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransitionOrBuilder getRegionsInTransitionOrBuilder(
        int index) {
      return regionsInTransition_.get(index);
    }
    
    // optional .ClusterId cluster_id = 5;
    public static final int CLUSTER_ID_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId clusterId_;
    public boolean hasClusterId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId getClusterId() {
      return clusterId_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterIdOrBuilder getClusterIdOrBuilder() {
      return clusterId_;
    }
    
    // repeated .Coprocessor master_coprocessors = 6;
    public static final int MASTER_COPROCESSORS_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> masterCoprocessors_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> getMasterCoprocessorsList() {
      return masterCoprocessors_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
        getMasterCoprocessorsOrBuilderList() {
      return masterCoprocessors_;
    }
    public int getMasterCoprocessorsCount() {
      return masterCoprocessors_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor getMasterCoprocessors(int index) {
      return masterCoprocessors_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder getMasterCoprocessorsOrBuilder(
        int index) {
      return masterCoprocessors_.get(index);
    }
    
    // optional .ServerName master = 7;
    public static final int MASTER_FIELD_NUMBER = 7;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName master_;
    public boolean hasMaster() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getMaster() {
      return master_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getMasterOrBuilder() {
      return master_;
    }
    
    // repeated .ServerName backup_masters = 8;
    public static final int BACKUP_MASTERS_FIELD_NUMBER = 8;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> backupMasters_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> getBackupMastersList() {
      return backupMasters_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
        getBackupMastersOrBuilderList() {
      return backupMasters_;
    }
    public int getBackupMastersCount() {
      return backupMasters_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getBackupMasters(int index) {
      return backupMasters_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getBackupMastersOrBuilder(
        int index) {
      return backupMasters_.get(index);
    }
    
    // optional bool balancer_on = 9;
    public static final int BALANCER_ON_FIELD_NUMBER = 9;
    private boolean balancerOn_;
    public boolean hasBalancerOn() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public boolean getBalancerOn() {
      return balancerOn_;
    }
    
    private void initFields() {
      hbaseVersion_ = org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.getDefaultInstance();
      liveServers_ = java.util.Collections.emptyList();
      deadServers_ = java.util.Collections.emptyList();
      regionsInTransition_ = java.util.Collections.emptyList();
      clusterId_ = org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.getDefaultInstance();
      masterCoprocessors_ = java.util.Collections.emptyList();
      master_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
      backupMasters_ = java.util.Collections.emptyList();
      balancerOn_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (hasHbaseVersion()) {
        if (!getHbaseVersion().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getLiveServersCount(); i++) {
        if (!getLiveServers(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getDeadServersCount(); i++) {
        if (!getDeadServers(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getRegionsInTransitionCount(); i++) {
        if (!getRegionsInTransition(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasClusterId()) {
        if (!getClusterId().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getMasterCoprocessorsCount(); i++) {
        if (!getMasterCoprocessors(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasMaster()) {
        if (!getMaster().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getBackupMastersCount(); i++) {
        if (!getBackupMasters(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, hbaseVersion_);
      }
      for (int i = 0; i < liveServers_.size(); i++) {
        output.writeMessage(2, liveServers_.get(i));
      }
      for (int i = 0; i < deadServers_.size(); i++) {
        output.writeMessage(3, deadServers_.get(i));
      }
      for (int i = 0; i < regionsInTransition_.size(); i++) {
        output.writeMessage(4, regionsInTransition_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(5, clusterId_);
      }
      for (int i = 0; i < masterCoprocessors_.size(); i++) {
        output.writeMessage(6, masterCoprocessors_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(7, master_);
      }
      for (int i = 0; i < backupMasters_.size(); i++) {
        output.writeMessage(8, backupMasters_.get(i));
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBool(9, balancerOn_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, hbaseVersion_);
      }
      for (int i = 0; i < liveServers_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, liveServers_.get(i));
      }
      for (int i = 0; i < deadServers_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, deadServers_.get(i));
      }
      for (int i = 0; i < regionsInTransition_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, regionsInTransition_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, clusterId_);
      }
      for (int i = 0; i < masterCoprocessors_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, masterCoprocessors_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, master_);
      }
      for (int i = 0; i < backupMasters_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, backupMasters_.get(i));
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(9, balancerOn_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus other = (org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus) obj;
      
      boolean result = true;
      result = result && (hasHbaseVersion() == other.hasHbaseVersion());
      if (hasHbaseVersion()) {
        result = result && getHbaseVersion()
            .equals(other.getHbaseVersion());
      }
      result = result && getLiveServersList()
          .equals(other.getLiveServersList());
      result = result && getDeadServersList()
          .equals(other.getDeadServersList());
      result = result && getRegionsInTransitionList()
          .equals(other.getRegionsInTransitionList());
      result = result && (hasClusterId() == other.hasClusterId());
      if (hasClusterId()) {
        result = result && getClusterId()
            .equals(other.getClusterId());
      }
      result = result && getMasterCoprocessorsList()
          .equals(other.getMasterCoprocessorsList());
      result = result && (hasMaster() == other.hasMaster());
      if (hasMaster()) {
        result = result && getMaster()
            .equals(other.getMaster());
      }
      result = result && getBackupMastersList()
          .equals(other.getBackupMastersList());
      result = result && (hasBalancerOn() == other.hasBalancerOn());
      if (hasBalancerOn()) {
        result = result && (getBalancerOn()
            == other.getBalancerOn());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasHbaseVersion()) {
        hash = (37 * hash) + HBASE_VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getHbaseVersion().hashCode();
      }
      if (getLiveServersCount() > 0) {
        hash = (37 * hash) + LIVE_SERVERS_FIELD_NUMBER;
        hash = (53 * hash) + getLiveServersList().hashCode();
      }
      if (getDeadServersCount() > 0) {
        hash = (37 * hash) + DEAD_SERVERS_FIELD_NUMBER;
        hash = (53 * hash) + getDeadServersList().hashCode();
      }
      if (getRegionsInTransitionCount() > 0) {
        hash = (37 * hash) + REGIONS_IN_TRANSITION_FIELD_NUMBER;
        hash = (53 * hash) + getRegionsInTransitionList().hashCode();
      }
      if (hasClusterId()) {
        hash = (37 * hash) + CLUSTER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getClusterId().hashCode();
      }
      if (getMasterCoprocessorsCount() > 0) {
        hash = (37 * hash) + MASTER_COPROCESSORS_FIELD_NUMBER;
        hash = (53 * hash) + getMasterCoprocessorsList().hashCode();
      }
      if (hasMaster()) {
        hash = (37 * hash) + MASTER_FIELD_NUMBER;
        hash = (53 * hash) + getMaster().hashCode();
      }
      if (getBackupMastersCount() > 0) {
        hash = (37 * hash) + BACKUP_MASTERS_FIELD_NUMBER;
        hash = (53 * hash) + getBackupMastersList().hashCode();
      }
      if (hasBalancerOn()) {
        hash = (37 * hash) + BALANCER_ON_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getBalancerOn());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatusOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_ClusterStatus_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.internal_static_ClusterStatus_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getHbaseVersionFieldBuilder();
          getLiveServersFieldBuilder();
          getDeadServersFieldBuilder();
          getRegionsInTransitionFieldBuilder();
          getClusterIdFieldBuilder();
          getMasterCoprocessorsFieldBuilder();
          getMasterFieldBuilder();
          getBackupMastersFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (hbaseVersionBuilder_ == null) {
          hbaseVersion_ = org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.getDefaultInstance();
        } else {
          hbaseVersionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (liveServersBuilder_ == null) {
          liveServers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          liveServersBuilder_.clear();
        }
        if (deadServersBuilder_ == null) {
          deadServers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          deadServersBuilder_.clear();
        }
        if (regionsInTransitionBuilder_ == null) {
          regionsInTransition_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          regionsInTransitionBuilder_.clear();
        }
        if (clusterIdBuilder_ == null) {
          clusterId_ = org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.getDefaultInstance();
        } else {
          clusterIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        if (masterCoprocessorsBuilder_ == null) {
          masterCoprocessors_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          masterCoprocessorsBuilder_.clear();
        }
        if (masterBuilder_ == null) {
          master_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
        } else {
          masterBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        if (backupMastersBuilder_ == null) {
          backupMasters_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000080);
        } else {
          backupMastersBuilder_.clear();
        }
        balancerOn_ = false;
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus build() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus result = new org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (hbaseVersionBuilder_ == null) {
          result.hbaseVersion_ = hbaseVersion_;
        } else {
          result.hbaseVersion_ = hbaseVersionBuilder_.build();
        }
        if (liveServersBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            liveServers_ = java.util.Collections.unmodifiableList(liveServers_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.liveServers_ = liveServers_;
        } else {
          result.liveServers_ = liveServersBuilder_.build();
        }
        if (deadServersBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            deadServers_ = java.util.Collections.unmodifiableList(deadServers_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.deadServers_ = deadServers_;
        } else {
          result.deadServers_ = deadServersBuilder_.build();
        }
        if (regionsInTransitionBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            regionsInTransition_ = java.util.Collections.unmodifiableList(regionsInTransition_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.regionsInTransition_ = regionsInTransition_;
        } else {
          result.regionsInTransition_ = regionsInTransitionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000002;
        }
        if (clusterIdBuilder_ == null) {
          result.clusterId_ = clusterId_;
        } else {
          result.clusterId_ = clusterIdBuilder_.build();
        }
        if (masterCoprocessorsBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            masterCoprocessors_ = java.util.Collections.unmodifiableList(masterCoprocessors_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.masterCoprocessors_ = masterCoprocessors_;
        } else {
          result.masterCoprocessors_ = masterCoprocessorsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000004;
        }
        if (masterBuilder_ == null) {
          result.master_ = master_;
        } else {
          result.master_ = masterBuilder_.build();
        }
        if (backupMastersBuilder_ == null) {
          if (((bitField0_ & 0x00000080) == 0x00000080)) {
            backupMasters_ = java.util.Collections.unmodifiableList(backupMasters_);
            bitField0_ = (bitField0_ & ~0x00000080);
          }
          result.backupMasters_ = backupMasters_;
        } else {
          result.backupMasters_ = backupMastersBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000008;
        }
        result.balancerOn_ = balancerOn_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus.getDefaultInstance()) return this;
        if (other.hasHbaseVersion()) {
          mergeHbaseVersion(other.getHbaseVersion());
        }
        if (liveServersBuilder_ == null) {
          if (!other.liveServers_.isEmpty()) {
            if (liveServers_.isEmpty()) {
              liveServers_ = other.liveServers_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureLiveServersIsMutable();
              liveServers_.addAll(other.liveServers_);
            }
            onChanged();
          }
        } else {
          if (!other.liveServers_.isEmpty()) {
            if (liveServersBuilder_.isEmpty()) {
              liveServersBuilder_.dispose();
              liveServersBuilder_ = null;
              liveServers_ = other.liveServers_;
              bitField0_ = (bitField0_ & ~0x00000002);
              liveServersBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getLiveServersFieldBuilder() : null;
            } else {
              liveServersBuilder_.addAllMessages(other.liveServers_);
            }
          }
        }
        if (deadServersBuilder_ == null) {
          if (!other.deadServers_.isEmpty()) {
            if (deadServers_.isEmpty()) {
              deadServers_ = other.deadServers_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureDeadServersIsMutable();
              deadServers_.addAll(other.deadServers_);
            }
            onChanged();
          }
        } else {
          if (!other.deadServers_.isEmpty()) {
            if (deadServersBuilder_.isEmpty()) {
              deadServersBuilder_.dispose();
              deadServersBuilder_ = null;
              deadServers_ = other.deadServers_;
              bitField0_ = (bitField0_ & ~0x00000004);
              deadServersBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getDeadServersFieldBuilder() : null;
            } else {
              deadServersBuilder_.addAllMessages(other.deadServers_);
            }
          }
        }
        if (regionsInTransitionBuilder_ == null) {
          if (!other.regionsInTransition_.isEmpty()) {
            if (regionsInTransition_.isEmpty()) {
              regionsInTransition_ = other.regionsInTransition_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureRegionsInTransitionIsMutable();
              regionsInTransition_.addAll(other.regionsInTransition_);
            }
            onChanged();
          }
        } else {
          if (!other.regionsInTransition_.isEmpty()) {
            if (regionsInTransitionBuilder_.isEmpty()) {
              regionsInTransitionBuilder_.dispose();
              regionsInTransitionBuilder_ = null;
              regionsInTransition_ = other.regionsInTransition_;
              bitField0_ = (bitField0_ & ~0x00000008);
              regionsInTransitionBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getRegionsInTransitionFieldBuilder() : null;
            } else {
              regionsInTransitionBuilder_.addAllMessages(other.regionsInTransition_);
            }
          }
        }
        if (other.hasClusterId()) {
          mergeClusterId(other.getClusterId());
        }
        if (masterCoprocessorsBuilder_ == null) {
          if (!other.masterCoprocessors_.isEmpty()) {
            if (masterCoprocessors_.isEmpty()) {
              masterCoprocessors_ = other.masterCoprocessors_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureMasterCoprocessorsIsMutable();
              masterCoprocessors_.addAll(other.masterCoprocessors_);
            }
            onChanged();
          }
        } else {
          if (!other.masterCoprocessors_.isEmpty()) {
            if (masterCoprocessorsBuilder_.isEmpty()) {
              masterCoprocessorsBuilder_.dispose();
              masterCoprocessorsBuilder_ = null;
              masterCoprocessors_ = other.masterCoprocessors_;
              bitField0_ = (bitField0_ & ~0x00000020);
              masterCoprocessorsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getMasterCoprocessorsFieldBuilder() : null;
            } else {
              masterCoprocessorsBuilder_.addAllMessages(other.masterCoprocessors_);
            }
          }
        }
        if (other.hasMaster()) {
          mergeMaster(other.getMaster());
        }
        if (backupMastersBuilder_ == null) {
          if (!other.backupMasters_.isEmpty()) {
            if (backupMasters_.isEmpty()) {
              backupMasters_ = other.backupMasters_;
              bitField0_ = (bitField0_ & ~0x00000080);
            } else {
              ensureBackupMastersIsMutable();
              backupMasters_.addAll(other.backupMasters_);
            }
            onChanged();
          }
        } else {
          if (!other.backupMasters_.isEmpty()) {
            if (backupMastersBuilder_.isEmpty()) {
              backupMastersBuilder_.dispose();
              backupMastersBuilder_ = null;
              backupMasters_ = other.backupMasters_;
              bitField0_ = (bitField0_ & ~0x00000080);
              backupMastersBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getBackupMastersFieldBuilder() : null;
            } else {
              backupMastersBuilder_.addAllMessages(other.backupMasters_);
            }
          }
        }
        if (other.hasBalancerOn()) {
          setBalancerOn(other.getBalancerOn());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (hasHbaseVersion()) {
          if (!getHbaseVersion().isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getLiveServersCount(); i++) {
          if (!getLiveServers(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getDeadServersCount(); i++) {
          if (!getDeadServers(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getRegionsInTransitionCount(); i++) {
          if (!getRegionsInTransition(i).isInitialized()) {
            
            return false;
          }
        }
        if (hasClusterId()) {
          if (!getClusterId().isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getMasterCoprocessorsCount(); i++) {
          if (!getMasterCoprocessors(i).isInitialized()) {
            
            return false;
          }
        }
        if (hasMaster()) {
          if (!getMaster().isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getBackupMastersCount(); i++) {
          if (!getBackupMasters(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.newBuilder();
              if (hasHbaseVersion()) {
                subBuilder.mergeFrom(getHbaseVersion());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setHbaseVersion(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addLiveServers(subBuilder.buildPartial());
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addDeadServers(subBuilder.buildPartial());
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addRegionsInTransition(subBuilder.buildPartial());
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.newBuilder();
              if (hasClusterId()) {
                subBuilder.mergeFrom(getClusterId());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setClusterId(subBuilder.buildPartial());
              break;
            }
            case 50: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addMasterCoprocessors(subBuilder.buildPartial());
              break;
            }
            case 58: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.newBuilder();
              if (hasMaster()) {
                subBuilder.mergeFrom(getMaster());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setMaster(subBuilder.buildPartial());
              break;
            }
            case 66: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addBackupMasters(subBuilder.buildPartial());
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              balancerOn_ = input.readBool();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .HBaseVersionFileContent hbase_version = 1;
      private org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent hbaseVersion_ = org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent, org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.Builder, org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContentOrBuilder> hbaseVersionBuilder_;
      public boolean hasHbaseVersion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent getHbaseVersion() {
        if (hbaseVersionBuilder_ == null) {
          return hbaseVersion_;
        } else {
          return hbaseVersionBuilder_.getMessage();
        }
      }
      public Builder setHbaseVersion(org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent value) {
        if (hbaseVersionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          hbaseVersion_ = value;
          onChanged();
        } else {
          hbaseVersionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setHbaseVersion(
          org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.Builder builderForValue) {
        if (hbaseVersionBuilder_ == null) {
          hbaseVersion_ = builderForValue.build();
          onChanged();
        } else {
          hbaseVersionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeHbaseVersion(org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent value) {
        if (hbaseVersionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              hbaseVersion_ != org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.getDefaultInstance()) {
            hbaseVersion_ =
              org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.newBuilder(hbaseVersion_).mergeFrom(value).buildPartial();
          } else {
            hbaseVersion_ = value;
          }
          onChanged();
        } else {
          hbaseVersionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearHbaseVersion() {
        if (hbaseVersionBuilder_ == null) {
          hbaseVersion_ = org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.getDefaultInstance();
          onChanged();
        } else {
          hbaseVersionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.Builder getHbaseVersionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getHbaseVersionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContentOrBuilder getHbaseVersionOrBuilder() {
        if (hbaseVersionBuilder_ != null) {
          return hbaseVersionBuilder_.getMessageOrBuilder();
        } else {
          return hbaseVersion_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent, org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.Builder, org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContentOrBuilder> 
          getHbaseVersionFieldBuilder() {
        if (hbaseVersionBuilder_ == null) {
          hbaseVersionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent, org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContent.Builder, org.apache.hadoop.hbase.protobuf.generated.FSProtos.HBaseVersionFileContentOrBuilder>(
                  hbaseVersion_,
                  getParentForChildren(),
                  isClean());
          hbaseVersion_ = null;
        }
        return hbaseVersionBuilder_;
      }
      
      // repeated .LiveServerInfo live_servers = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo> liveServers_ =
        java.util.Collections.emptyList();
      private void ensureLiveServersIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          liveServers_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo>(liveServers_);
          bitField0_ |= 0x00000002;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfoOrBuilder> liveServersBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo> getLiveServersList() {
        if (liveServersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(liveServers_);
        } else {
          return liveServersBuilder_.getMessageList();
        }
      }
      public int getLiveServersCount() {
        if (liveServersBuilder_ == null) {
          return liveServers_.size();
        } else {
          return liveServersBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo getLiveServers(int index) {
        if (liveServersBuilder_ == null) {
          return liveServers_.get(index);
        } else {
          return liveServersBuilder_.getMessage(index);
        }
      }
      public Builder setLiveServers(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo value) {
        if (liveServersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLiveServersIsMutable();
          liveServers_.set(index, value);
          onChanged();
        } else {
          liveServersBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setLiveServers(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder builderForValue) {
        if (liveServersBuilder_ == null) {
          ensureLiveServersIsMutable();
          liveServers_.set(index, builderForValue.build());
          onChanged();
        } else {
          liveServersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addLiveServers(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo value) {
        if (liveServersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLiveServersIsMutable();
          liveServers_.add(value);
          onChanged();
        } else {
          liveServersBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addLiveServers(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo value) {
        if (liveServersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLiveServersIsMutable();
          liveServers_.add(index, value);
          onChanged();
        } else {
          liveServersBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addLiveServers(
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder builderForValue) {
        if (liveServersBuilder_ == null) {
          ensureLiveServersIsMutable();
          liveServers_.add(builderForValue.build());
          onChanged();
        } else {
          liveServersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addLiveServers(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder builderForValue) {
        if (liveServersBuilder_ == null) {
          ensureLiveServersIsMutable();
          liveServers_.add(index, builderForValue.build());
          onChanged();
        } else {
          liveServersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllLiveServers(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo> values) {
        if (liveServersBuilder_ == null) {
          ensureLiveServersIsMutable();
          super.addAll(values, liveServers_);
          onChanged();
        } else {
          liveServersBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearLiveServers() {
        if (liveServersBuilder_ == null) {
          liveServers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          liveServersBuilder_.clear();
        }
        return this;
      }
      public Builder removeLiveServers(int index) {
        if (liveServersBuilder_ == null) {
          ensureLiveServersIsMutable();
          liveServers_.remove(index);
          onChanged();
        } else {
          liveServersBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder getLiveServersBuilder(
          int index) {
        return getLiveServersFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfoOrBuilder getLiveServersOrBuilder(
          int index) {
        if (liveServersBuilder_ == null) {
          return liveServers_.get(index);  } else {
          return liveServersBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfoOrBuilder> 
           getLiveServersOrBuilderList() {
        if (liveServersBuilder_ != null) {
          return liveServersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(liveServers_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder addLiveServersBuilder() {
        return getLiveServersFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder addLiveServersBuilder(
          int index) {
        return getLiveServersFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder> 
           getLiveServersBuilderList() {
        return getLiveServersFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfoOrBuilder> 
          getLiveServersFieldBuilder() {
        if (liveServersBuilder_ == null) {
          liveServersBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfoOrBuilder>(
                  liveServers_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          liveServers_ = null;
        }
        return liveServersBuilder_;
      }
      
      // repeated .ServerName dead_servers = 3;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> deadServers_ =
        java.util.Collections.emptyList();
      private void ensureDeadServersIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          deadServers_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName>(deadServers_);
          bitField0_ |= 0x00000004;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> deadServersBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> getDeadServersList() {
        if (deadServersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(deadServers_);
        } else {
          return deadServersBuilder_.getMessageList();
        }
      }
      public int getDeadServersCount() {
        if (deadServersBuilder_ == null) {
          return deadServers_.size();
        } else {
          return deadServersBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getDeadServers(int index) {
        if (deadServersBuilder_ == null) {
          return deadServers_.get(index);
        } else {
          return deadServersBuilder_.getMessage(index);
        }
      }
      public Builder setDeadServers(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (deadServersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDeadServersIsMutable();
          deadServers_.set(index, value);
          onChanged();
        } else {
          deadServersBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setDeadServers(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (deadServersBuilder_ == null) {
          ensureDeadServersIsMutable();
          deadServers_.set(index, builderForValue.build());
          onChanged();
        } else {
          deadServersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addDeadServers(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (deadServersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDeadServersIsMutable();
          deadServers_.add(value);
          onChanged();
        } else {
          deadServersBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addDeadServers(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (deadServersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureDeadServersIsMutable();
          deadServers_.add(index, value);
          onChanged();
        } else {
          deadServersBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addDeadServers(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (deadServersBuilder_ == null) {
          ensureDeadServersIsMutable();
          deadServers_.add(builderForValue.build());
          onChanged();
        } else {
          deadServersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addDeadServers(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (deadServersBuilder_ == null) {
          ensureDeadServersIsMutable();
          deadServers_.add(index, builderForValue.build());
          onChanged();
        } else {
          deadServersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllDeadServers(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> values) {
        if (deadServersBuilder_ == null) {
          ensureDeadServersIsMutable();
          super.addAll(values, deadServers_);
          onChanged();
        } else {
          deadServersBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearDeadServers() {
        if (deadServersBuilder_ == null) {
          deadServers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          deadServersBuilder_.clear();
        }
        return this;
      }
      public Builder removeDeadServers(int index) {
        if (deadServersBuilder_ == null) {
          ensureDeadServersIsMutable();
          deadServers_.remove(index);
          onChanged();
        } else {
          deadServersBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder getDeadServersBuilder(
          int index) {
        return getDeadServersFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getDeadServersOrBuilder(
          int index) {
        if (deadServersBuilder_ == null) {
          return deadServers_.get(index);  } else {
          return deadServersBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
           getDeadServersOrBuilderList() {
        if (deadServersBuilder_ != null) {
          return deadServersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(deadServers_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder addDeadServersBuilder() {
        return getDeadServersFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder addDeadServersBuilder(
          int index) {
        return getDeadServersFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder> 
           getDeadServersBuilderList() {
        return getDeadServersFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getDeadServersFieldBuilder() {
        if (deadServersBuilder_ == null) {
          deadServersBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  deadServers_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          deadServers_ = null;
        }
        return deadServersBuilder_;
      }
      
      // repeated .RegionInTransition regions_in_transition = 4;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition> regionsInTransition_ =
        java.util.Collections.emptyList();
      private void ensureRegionsInTransitionIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          regionsInTransition_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition>(regionsInTransition_);
          bitField0_ |= 0x00000008;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransitionOrBuilder> regionsInTransitionBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition> getRegionsInTransitionList() {
        if (regionsInTransitionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionsInTransition_);
        } else {
          return regionsInTransitionBuilder_.getMessageList();
        }
      }
      public int getRegionsInTransitionCount() {
        if (regionsInTransitionBuilder_ == null) {
          return regionsInTransition_.size();
        } else {
          return regionsInTransitionBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition getRegionsInTransition(int index) {
        if (regionsInTransitionBuilder_ == null) {
          return regionsInTransition_.get(index);
        } else {
          return regionsInTransitionBuilder_.getMessage(index);
        }
      }
      public Builder setRegionsInTransition(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition value) {
        if (regionsInTransitionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsInTransitionIsMutable();
          regionsInTransition_.set(index, value);
          onChanged();
        } else {
          regionsInTransitionBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setRegionsInTransition(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder builderForValue) {
        if (regionsInTransitionBuilder_ == null) {
          ensureRegionsInTransitionIsMutable();
          regionsInTransition_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionsInTransitionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addRegionsInTransition(org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition value) {
        if (regionsInTransitionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsInTransitionIsMutable();
          regionsInTransition_.add(value);
          onChanged();
        } else {
          regionsInTransitionBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addRegionsInTransition(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition value) {
        if (regionsInTransitionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionsInTransitionIsMutable();
          regionsInTransition_.add(index, value);
          onChanged();
        } else {
          regionsInTransitionBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addRegionsInTransition(
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder builderForValue) {
        if (regionsInTransitionBuilder_ == null) {
          ensureRegionsInTransitionIsMutable();
          regionsInTransition_.add(builderForValue.build());
          onChanged();
        } else {
          regionsInTransitionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addRegionsInTransition(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder builderForValue) {
        if (regionsInTransitionBuilder_ == null) {
          ensureRegionsInTransitionIsMutable();
          regionsInTransition_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionsInTransitionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllRegionsInTransition(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition> values) {
        if (regionsInTransitionBuilder_ == null) {
          ensureRegionsInTransitionIsMutable();
          super.addAll(values, regionsInTransition_);
          onChanged();
        } else {
          regionsInTransitionBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearRegionsInTransition() {
        if (regionsInTransitionBuilder_ == null) {
          regionsInTransition_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          regionsInTransitionBuilder_.clear();
        }
        return this;
      }
      public Builder removeRegionsInTransition(int index) {
        if (regionsInTransitionBuilder_ == null) {
          ensureRegionsInTransitionIsMutable();
          regionsInTransition_.remove(index);
          onChanged();
        } else {
          regionsInTransitionBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder getRegionsInTransitionBuilder(
          int index) {
        return getRegionsInTransitionFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransitionOrBuilder getRegionsInTransitionOrBuilder(
          int index) {
        if (regionsInTransitionBuilder_ == null) {
          return regionsInTransition_.get(index);  } else {
          return regionsInTransitionBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransitionOrBuilder> 
           getRegionsInTransitionOrBuilderList() {
        if (regionsInTransitionBuilder_ != null) {
          return regionsInTransitionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionsInTransition_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder addRegionsInTransitionBuilder() {
        return getRegionsInTransitionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder addRegionsInTransitionBuilder(
          int index) {
        return getRegionsInTransitionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder> 
           getRegionsInTransitionBuilderList() {
        return getRegionsInTransitionFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransitionOrBuilder> 
          getRegionsInTransitionFieldBuilder() {
        if (regionsInTransitionBuilder_ == null) {
          regionsInTransitionBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransitionOrBuilder>(
                  regionsInTransition_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          regionsInTransition_ = null;
        }
        return regionsInTransitionBuilder_;
      }
      
      // optional .ClusterId cluster_id = 5;
      private org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId clusterId_ = org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId, org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterIdOrBuilder> clusterIdBuilder_;
      public boolean hasClusterId() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId getClusterId() {
        if (clusterIdBuilder_ == null) {
          return clusterId_;
        } else {
          return clusterIdBuilder_.getMessage();
        }
      }
      public Builder setClusterId(org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId value) {
        if (clusterIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          clusterId_ = value;
          onChanged();
        } else {
          clusterIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder setClusterId(
          org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.Builder builderForValue) {
        if (clusterIdBuilder_ == null) {
          clusterId_ = builderForValue.build();
          onChanged();
        } else {
          clusterIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder mergeClusterId(org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId value) {
        if (clusterIdBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              clusterId_ != org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.getDefaultInstance()) {
            clusterId_ =
              org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.newBuilder(clusterId_).mergeFrom(value).buildPartial();
          } else {
            clusterId_ = value;
          }
          onChanged();
        } else {
          clusterIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder clearClusterId() {
        if (clusterIdBuilder_ == null) {
          clusterId_ = org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.getDefaultInstance();
          onChanged();
        } else {
          clusterIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.Builder getClusterIdBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getClusterIdFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterIdOrBuilder getClusterIdOrBuilder() {
        if (clusterIdBuilder_ != null) {
          return clusterIdBuilder_.getMessageOrBuilder();
        } else {
          return clusterId_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId, org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterIdOrBuilder> 
          getClusterIdFieldBuilder() {
        if (clusterIdBuilder_ == null) {
          clusterIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId, org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterId.Builder, org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.ClusterIdOrBuilder>(
                  clusterId_,
                  getParentForChildren(),
                  isClean());
          clusterId_ = null;
        }
        return clusterIdBuilder_;
      }
      
      // repeated .Coprocessor master_coprocessors = 6;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> masterCoprocessors_ =
        java.util.Collections.emptyList();
      private void ensureMasterCoprocessorsIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          masterCoprocessors_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor>(masterCoprocessors_);
          bitField0_ |= 0x00000020;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> masterCoprocessorsBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> getMasterCoprocessorsList() {
        if (masterCoprocessorsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(masterCoprocessors_);
        } else {
          return masterCoprocessorsBuilder_.getMessageList();
        }
      }
      public int getMasterCoprocessorsCount() {
        if (masterCoprocessorsBuilder_ == null) {
          return masterCoprocessors_.size();
        } else {
          return masterCoprocessorsBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor getMasterCoprocessors(int index) {
        if (masterCoprocessorsBuilder_ == null) {
          return masterCoprocessors_.get(index);
        } else {
          return masterCoprocessorsBuilder_.getMessage(index);
        }
      }
      public Builder setMasterCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor value) {
        if (masterCoprocessorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMasterCoprocessorsIsMutable();
          masterCoprocessors_.set(index, value);
          onChanged();
        } else {
          masterCoprocessorsBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setMasterCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder builderForValue) {
        if (masterCoprocessorsBuilder_ == null) {
          ensureMasterCoprocessorsIsMutable();
          masterCoprocessors_.set(index, builderForValue.build());
          onChanged();
        } else {
          masterCoprocessorsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addMasterCoprocessors(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor value) {
        if (masterCoprocessorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMasterCoprocessorsIsMutable();
          masterCoprocessors_.add(value);
          onChanged();
        } else {
          masterCoprocessorsBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addMasterCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor value) {
        if (masterCoprocessorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureMasterCoprocessorsIsMutable();
          masterCoprocessors_.add(index, value);
          onChanged();
        } else {
          masterCoprocessorsBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addMasterCoprocessors(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder builderForValue) {
        if (masterCoprocessorsBuilder_ == null) {
          ensureMasterCoprocessorsIsMutable();
          masterCoprocessors_.add(builderForValue.build());
          onChanged();
        } else {
          masterCoprocessorsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addMasterCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder builderForValue) {
        if (masterCoprocessorsBuilder_ == null) {
          ensureMasterCoprocessorsIsMutable();
          masterCoprocessors_.add(index, builderForValue.build());
          onChanged();
        } else {
          masterCoprocessorsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllMasterCoprocessors(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> values) {
        if (masterCoprocessorsBuilder_ == null) {
          ensureMasterCoprocessorsIsMutable();
          super.addAll(values, masterCoprocessors_);
          onChanged();
        } else {
          masterCoprocessorsBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearMasterCoprocessors() {
        if (masterCoprocessorsBuilder_ == null) {
          masterCoprocessors_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          masterCoprocessorsBuilder_.clear();
        }
        return this;
      }
      public Builder removeMasterCoprocessors(int index) {
        if (masterCoprocessorsBuilder_ == null) {
          ensureMasterCoprocessorsIsMutable();
          masterCoprocessors_.remove(index);
          onChanged();
        } else {
          masterCoprocessorsBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder getMasterCoprocessorsBuilder(
          int index) {
        return getMasterCoprocessorsFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder getMasterCoprocessorsOrBuilder(
          int index) {
        if (masterCoprocessorsBuilder_ == null) {
          return masterCoprocessors_.get(index);  } else {
          return masterCoprocessorsBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
           getMasterCoprocessorsOrBuilderList() {
        if (masterCoprocessorsBuilder_ != null) {
          return masterCoprocessorsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(masterCoprocessors_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder addMasterCoprocessorsBuilder() {
        return getMasterCoprocessorsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder addMasterCoprocessorsBuilder(
          int index) {
        return getMasterCoprocessorsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder> 
           getMasterCoprocessorsBuilderList() {
        return getMasterCoprocessorsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
          getMasterCoprocessorsFieldBuilder() {
        if (masterCoprocessorsBuilder_ == null) {
          masterCoprocessorsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder>(
                  masterCoprocessors_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          masterCoprocessors_ = null;
        }
        return masterCoprocessorsBuilder_;
      }
      
      // optional .ServerName master = 7;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName master_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> masterBuilder_;
      public boolean hasMaster() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getMaster() {
        if (masterBuilder_ == null) {
          return master_;
        } else {
          return masterBuilder_.getMessage();
        }
      }
      public Builder setMaster(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (masterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          master_ = value;
          onChanged();
        } else {
          masterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      public Builder setMaster(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (masterBuilder_ == null) {
          master_ = builderForValue.build();
          onChanged();
        } else {
          masterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      public Builder mergeMaster(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (masterBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040) &&
              master_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) {
            master_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.newBuilder(master_).mergeFrom(value).buildPartial();
          } else {
            master_ = value;
          }
          onChanged();
        } else {
          masterBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      public Builder clearMaster() {
        if (masterBuilder_ == null) {
          master_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
          onChanged();
        } else {
          masterBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder getMasterBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getMasterFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getMasterOrBuilder() {
        if (masterBuilder_ != null) {
          return masterBuilder_.getMessageOrBuilder();
        } else {
          return master_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getMasterFieldBuilder() {
        if (masterBuilder_ == null) {
          masterBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  master_,
                  getParentForChildren(),
                  isClean());
          master_ = null;
        }
        return masterBuilder_;
      }
      
      // repeated .ServerName backup_masters = 8;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> backupMasters_ =
        java.util.Collections.emptyList();
      private void ensureBackupMastersIsMutable() {
        if (!((bitField0_ & 0x00000080) == 0x00000080)) {
          backupMasters_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName>(backupMasters_);
          bitField0_ |= 0x00000080;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> backupMastersBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> getBackupMastersList() {
        if (backupMastersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(backupMasters_);
        } else {
          return backupMastersBuilder_.getMessageList();
        }
      }
      public int getBackupMastersCount() {
        if (backupMastersBuilder_ == null) {
          return backupMasters_.size();
        } else {
          return backupMastersBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getBackupMasters(int index) {
        if (backupMastersBuilder_ == null) {
          return backupMasters_.get(index);
        } else {
          return backupMastersBuilder_.getMessage(index);
        }
      }
      public Builder setBackupMasters(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (backupMastersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureBackupMastersIsMutable();
          backupMasters_.set(index, value);
          onChanged();
        } else {
          backupMastersBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setBackupMasters(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (backupMastersBuilder_ == null) {
          ensureBackupMastersIsMutable();
          backupMasters_.set(index, builderForValue.build());
          onChanged();
        } else {
          backupMastersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addBackupMasters(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (backupMastersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureBackupMastersIsMutable();
          backupMasters_.add(value);
          onChanged();
        } else {
          backupMastersBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addBackupMasters(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName value) {
        if (backupMastersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureBackupMastersIsMutable();
          backupMasters_.add(index, value);
          onChanged();
        } else {
          backupMastersBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addBackupMasters(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (backupMastersBuilder_ == null) {
          ensureBackupMastersIsMutable();
          backupMasters_.add(builderForValue.build());
          onChanged();
        } else {
          backupMastersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addBackupMasters(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder builderForValue) {
        if (backupMastersBuilder_ == null) {
          ensureBackupMastersIsMutable();
          backupMasters_.add(index, builderForValue.build());
          onChanged();
        } else {
          backupMastersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllBackupMasters(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName> values) {
        if (backupMastersBuilder_ == null) {
          ensureBackupMastersIsMutable();
          super.addAll(values, backupMasters_);
          onChanged();
        } else {
          backupMastersBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearBackupMasters() {
        if (backupMastersBuilder_ == null) {
          backupMasters_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000080);
          onChanged();
        } else {
          backupMastersBuilder_.clear();
        }
        return this;
      }
      public Builder removeBackupMasters(int index) {
        if (backupMastersBuilder_ == null) {
          ensureBackupMastersIsMutable();
          backupMasters_.remove(index);
          onChanged();
        } else {
          backupMastersBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder getBackupMastersBuilder(
          int index) {
        return getBackupMastersFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder getBackupMastersOrBuilder(
          int index) {
        if (backupMastersBuilder_ == null) {
          return backupMasters_.get(index);  } else {
          return backupMastersBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
           getBackupMastersOrBuilderList() {
        if (backupMastersBuilder_ != null) {
          return backupMastersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(backupMasters_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder addBackupMastersBuilder() {
        return getBackupMastersFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder addBackupMastersBuilder(
          int index) {
        return getBackupMastersFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder> 
           getBackupMastersBuilderList() {
        return getBackupMastersFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder> 
          getBackupMastersFieldBuilder() {
        if (backupMastersBuilder_ == null) {
          backupMastersBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder>(
                  backupMasters_,
                  ((bitField0_ & 0x00000080) == 0x00000080),
                  getParentForChildren(),
                  isClean());
          backupMasters_ = null;
        }
        return backupMastersBuilder_;
      }
      
      // optional bool balancer_on = 9;
      private boolean balancerOn_ ;
      public boolean hasBalancerOn() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      public boolean getBalancerOn() {
        return balancerOn_;
      }
      public Builder setBalancerOn(boolean value) {
        bitField0_ |= 0x00000100;
        balancerOn_ = value;
        onChanged();
        return this;
      }
      public Builder clearBalancerOn() {
        bitField0_ = (bitField0_ & ~0x00000100);
        balancerOn_ = false;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:ClusterStatus)
    }
    
    static {
      defaultInstance = new ClusterStatus(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:ClusterStatus)
  }
  
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_RegionState_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_RegionState_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_RegionInTransition_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_RegionInTransition_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_RegionLoad_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_RegionLoad_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ServerLoad_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ServerLoad_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_LiveServerInfo_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_LiveServerInfo_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ClusterStatus_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ClusterStatus_fieldAccessorTable;
  
  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\023ClusterStatus.proto\032\013hbase.proto\032\017Clus" +
      "terId.proto\032\010FS.proto\"\243\002\n\013RegionState\022 \n" +
      "\013region_info\030\001 \002(\0132\013.RegionInfo\022!\n\005state" +
      "\030\002 \002(\0162\022.RegionState.State\022\r\n\005stamp\030\003 \001(" +
      "\004\"\277\001\n\005State\022\013\n\007OFFLINE\020\000\022\020\n\014PENDING_OPEN" +
      "\020\001\022\013\n\007OPENING\020\002\022\010\n\004OPEN\020\003\022\021\n\rPENDING_CLO" +
      "SE\020\004\022\013\n\007CLOSING\020\005\022\n\n\006CLOSED\020\006\022\r\n\tSPLITTI" +
      "NG\020\007\022\t\n\005SPLIT\020\010\022\017\n\013FAILED_OPEN\020\t\022\020\n\014FAIL" +
      "ED_CLOSE\020\n\022\013\n\007MERGING\020\013\022\n\n\006MERGED\020\014\"X\n\022R" +
      "egionInTransition\022\036\n\004spec\030\001 \002(\0132\020.Region",
      "Specifier\022\"\n\014region_state\030\002 \002(\0132\014.Region" +
      "State\"\320\003\n\nRegionLoad\022*\n\020region_specifier" +
      "\030\001 \002(\0132\020.RegionSpecifier\022\016\n\006stores\030\002 \001(\r" +
      "\022\022\n\nstorefiles\030\003 \001(\r\022\"\n\032store_uncompress" +
      "ed_size_MB\030\004 \001(\r\022\031\n\021storefile_size_MB\030\005 " +
      "\001(\r\022\030\n\020memstore_size_MB\030\006 \001(\r\022\037\n\027storefi" +
      "le_index_size_MB\030\007 \001(\r\022\033\n\023read_requests_" +
      "count\030\010 \001(\004\022\034\n\024write_requests_count\030\t \001(" +
      "\004\022\034\n\024total_compacting_KVs\030\n \001(\004\022\035\n\025curre" +
      "nt_compacted_KVs\030\013 \001(\004\022\032\n\022root_index_siz",
      "e_KB\030\014 \001(\r\022\"\n\032total_static_index_size_KB" +
      "\030\r \001(\r\022\"\n\032total_static_bloom_size_KB\030\016 \001" +
      "(\r\022\034\n\024complete_sequence_id\030\017 \001(\004\"\212\002\n\nSer" +
      "verLoad\022\032\n\022number_of_requests\030\001 \001(\r\022 \n\030t" +
      "otal_number_of_requests\030\002 \001(\r\022\024\n\014used_he" +
      "ap_MB\030\003 \001(\r\022\023\n\013max_heap_MB\030\004 \001(\r\022!\n\014regi" +
      "on_loads\030\005 \003(\0132\013.RegionLoad\022\"\n\014coprocess" +
      "ors\030\006 \003(\0132\014.Coprocessor\022\031\n\021report_start_" +
      "time\030\007 \001(\004\022\027\n\017report_end_time\030\010 \001(\004\022\030\n\020i" +
      "nfo_server_port\030\t \001(\r\"O\n\016LiveServerInfo\022",
      "\033\n\006server\030\001 \002(\0132\013.ServerName\022 \n\013server_l" +
      "oad\030\002 \002(\0132\013.ServerLoad\"\340\002\n\rClusterStatus" +
      "\022/\n\rhbase_version\030\001 \001(\0132\030.HBaseVersionFi" +
      "leContent\022%\n\014live_servers\030\002 \003(\0132\017.LiveSe" +
      "rverInfo\022!\n\014dead_servers\030\003 \003(\0132\013.ServerN" +
      "ame\0222\n\025regions_in_transition\030\004 \003(\0132\023.Reg" +
      "ionInTransition\022\036\n\ncluster_id\030\005 \001(\0132\n.Cl" +
      "usterId\022)\n\023master_coprocessors\030\006 \003(\0132\014.C" +
      "oprocessor\022\033\n\006master\030\007 \001(\0132\013.ServerName\022" +
      "#\n\016backup_masters\030\010 \003(\0132\013.ServerName\022\023\n\013",
      "balancer_on\030\t \001(\010BF\n*org.apache.hadoop.h" +
      "base.protobuf.generatedB\023ClusterStatusPr" +
      "otosH\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_RegionState_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_RegionState_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_RegionState_descriptor,
              new java.lang.String[] { "RegionInfo", "State", "Stamp", },
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.class,
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionState.Builder.class);
          internal_static_RegionInTransition_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_RegionInTransition_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_RegionInTransition_descriptor,
              new java.lang.String[] { "Spec", "RegionState", },
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.class,
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionInTransition.Builder.class);
          internal_static_RegionLoad_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_RegionLoad_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_RegionLoad_descriptor,
              new java.lang.String[] { "RegionSpecifier", "Stores", "Storefiles", "StoreUncompressedSizeMB", "StorefileSizeMB", "MemstoreSizeMB", "StorefileIndexSizeMB", "ReadRequestsCount", "WriteRequestsCount", "TotalCompactingKVs", "CurrentCompactedKVs", "RootIndexSizeKB", "TotalStaticIndexSizeKB", "TotalStaticBloomSizeKB", "CompleteSequenceId", },
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.class,
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.RegionLoad.Builder.class);
          internal_static_ServerLoad_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_ServerLoad_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ServerLoad_descriptor,
              new java.lang.String[] { "NumberOfRequests", "TotalNumberOfRequests", "UsedHeapMB", "MaxHeapMB", "RegionLoads", "Coprocessors", "ReportStartTime", "ReportEndTime", "InfoServerPort", },
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.class,
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ServerLoad.Builder.class);
          internal_static_LiveServerInfo_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_LiveServerInfo_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_LiveServerInfo_descriptor,
              new java.lang.String[] { "Server", "ServerLoad", },
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.class,
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.LiveServerInfo.Builder.class);
          internal_static_ClusterStatus_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_ClusterStatus_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ClusterStatus_descriptor,
              new java.lang.String[] { "HbaseVersion", "LiveServers", "DeadServers", "RegionsInTransition", "ClusterId", "MasterCoprocessors", "Master", "BackupMasters", "BalancerOn", },
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus.class,
              org.apache.hadoop.hbase.protobuf.generated.ClusterStatusProtos.ClusterStatus.Builder.class);
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor(),
          org.apache.hadoop.hbase.protobuf.generated.ClusterIdProtos.getDescriptor(),
          org.apache.hadoop.hbase.protobuf.generated.FSProtos.getDescriptor(),
        }, assigner);
  }
  
  // @@protoc_insertion_point(outer_class_scope)
}
